<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>如何为私有大语言模型快速沉淀高质量数据集 | Kevinello</title><meta name="keywords" content="LLM,Prompt-Engineering,OpenAI"><meta name="author" content="Kevinello"><meta name="copyright" content="Kevinello"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="前言 在构建text-to-sql模型时，高质量的数据和有效的数据流程是必不可少的。目前市面上已经有许多优秀的开源大模型，如ChatLLaMa、Alpaca、Vicuna、以及Databricks-Dolly，Stable Diffution母公司发布的StableLM等 此外，还有一些训练框架可供选择，比如LMFlow和微软最近开源的DeepSpeed等 但即使开源的大模型和训练框架都越来越多"><meta property="og:type" content="article"><meta property="og:title" content="如何为私有大语言模型快速沉淀高质量数据集"><meta property="og:url" content="http://kevinello.ltd/2023/07/06/%E5%A6%82%E4%BD%95%E4%B8%BA%E7%A7%81%E6%9C%89%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BF%AB%E9%80%9F%E6%B2%89%E6%B7%80%E9%AB%98%E8%B4%A8%E9%87%8F%E6%95%B0%E6%8D%AE%E9%9B%86/index.html"><meta property="og:site_name" content="Kevinello"><meta property="og:description" content="前言 在构建text-to-sql模型时，高质量的数据和有效的数据流程是必不可少的。目前市面上已经有许多优秀的开源大模型，如ChatLLaMa、Alpaca、Vicuna、以及Databricks-Dolly，Stable Diffution母公司发布的StableLM等 此外，还有一些训练框架可供选择，比如LMFlow和微软最近开源的DeepSpeed等 但即使开源的大模型和训练框架都越来越多"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/09/07/202309071443770-70c1ed.png"><meta property="article:published_time" content="2023-07-05T16:08:35.000Z"><meta property="article:modified_time" content="2023-09-07T06:43:54.419Z"><meta property="article:author" content="Kevinello"><meta property="article:tag" content="LLM"><meta property="article:tag" content="Prompt-Engineering"><meta property="article:tag" content="OpenAI"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/09/07/202309071443770-70c1ed.png"><link rel="shortcut icon" href="/imgs/K.jpg"><link rel="canonical" href="http://kevinello.ltd/2023/07/06/%E5%A6%82%E4%BD%95%E4%B8%BA%E7%A7%81%E6%9C%89%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BF%AB%E9%80%9F%E6%B2%89%E6%B7%80%E9%AB%98%E8%B4%A8%E9%87%8F%E6%95%B0%E6%8D%AE%E9%9B%86/"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload='this.media="all"'><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?d2a20aecba22b2eaf60183c4831d9a52";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-RV8K5FBVX5"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RV8K5FBVX5")</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"13UJR6CRNO","apiKey":"456e56f51ec27a1e13d67bef144f6747","indexName":"Kevinello_blog","hits":{"per_page":6},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容：${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: {"limitDay":180,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"如何为私有大语言模型快速沉淀高质量数据集",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2023-09-07 14:43:54"}</script><noscript><style>#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="//at.alicdn.com/t/font_2232093_k6128tldgy.css"><meta name="generator" content="Hexo 5.2.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2022/04/11/myself-e3fde6.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">50</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">95</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(https://kevinello-1302687393.file.myqcloud.com/picgo/2023/09/07/202309071443770-70c1ed.png)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Kevinello</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i> <span>搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">如何为私有大语言模型快速沉淀高质量数据集</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-07-05T16:08:35.000Z" title="发表于 2023-07-06 00:08:35">2023-07-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-09-07T06:43:54.419Z" title="更新于 2023-09-07 14:43:54">2023-09-07</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/">技术文章</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>23分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="如何为私有大语言模型快速沉淀高质量数据集"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> <strong>前言</strong></h2><p>在构建<code>text-to-sql</code>模型时，高质量的数据和有效的数据流程是必不可少的。目前市面上已经有许多优秀的开源大模型，如<code>ChatLLaMa</code>、<code>Alpaca</code>、<code>Vicuna</code>、以及<code>Databricks-Dolly</code>，<code>Stable Diffution</code>母公司发布的<code>StableLM</code>等</p><p>此外，还有一些训练框架可供选择，比如<code>LMFlow</code>和微软最近开源的<code>DeepSpeed</code>等</p><p>但即使开源的大模型和训练框架都越来越多，它们也都离不开<strong>高质量数据和生产高质量数据的流程</strong>，这也是一切模型构建的前提；这篇文章就来讲一下在私有项目中我是如何持续积累高质量数据集，并沉淀相关流程框架的</p><h2 id="需要了解的词"><a class="markdownIt-Anchor" href="#需要了解的词"></a> <strong>需要了解的词</strong></h2><ul><li><p><strong>Prompt Engineering</strong></p><p>一种为生成式AI模型设计和提炼<code>prompt</code>的方法论 / 框架，通常是规定 / 限制从模型中获得所需输出的框架，并持续的通过实验和分析来优化这些<code>prompt</code></p><p><code>Prompt Engineering</code>很重要，因为它可以显著影响NLP模型的性能，特别是对于微调任务。设计良好的<code>prompt</code>可以使模型生成更准确和相关的响应，而设计不当的提示可能会导致不准确或无用的输出，<code>Prompt Engineering</code>能够帮助我们进行LLM对接、构建和理解其功能，并提高其安全性</p><p><code>Prompt Engineering</code>的常见技术包括限制<code>prompt</code>的长度和结构、合并上下文和背景知识，以及使用各种类型的提示，如填空式<code>prompt</code>、多项选择或自由格式文本<code>prompt</code></p></li><li><p><strong>OpenAI API 代理</strong></p><p>由于在国内ip直接调用OpenAI官方API可能会导致封号等问题，为了避免这些问题带来不必要的损失，我们通常还可以选择许多国内服务商提供的OpenAI API 代理服务，它们能以接近官方API的价格提供相同调用方式的代理服务（那些价格低于官方API价格的建议不要使用，往往是一些非独占token的服务，通过维护大量Free Granted账号实现，也并不稳定）</p></li></ul><h2 id="开源数据集"><a class="markdownIt-Anchor" href="#开源数据集"></a> <strong>开源数据集</strong></h2><p>在开源社区中存在着许多文本到<code>text-to-sql</code>数据集，包括但不限于<em>WikiSQL, SParC, Spider, HybridSQL, CoSQL</em>等。这些数据集可以作为模型的训练集、验证集和测试集，并且其高质量的标注使得它们有资格评价模型性能的标准，这些开源数据集通常也维护了一份<code>LeaderBoard</code>来<code>show</code>出使用它们训练出的模型表现，如下是我收集的来自<code>huggingface</code>, <code>paperswithcode</code>, <code>Github</code>的一些优质的<code>text-to-sql</code>数据集：</p><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/05/04/202305041000088-7fade9.png" alt="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/05/04/202305041000088-7fade9.png" style="zoom:25%"><p>这些数据集经过一些格式处理和信息补充，即可直接作为我们模型的训练数据集；格式处理过程这里不做过多阐述，完成格式处理后，还需经过数据校验以及SQL分析，这些功能由下面介绍的Prompt-Collector提供</p><h2 id="prompt-collector"><a class="markdownIt-Anchor" href="#prompt-collector"></a> <strong>Prompt-Collector</strong></h2><p>除了上面提到过的方式——使用已有的开源数据集，我们还可以通过基于<code>GPT-3.5</code>这个已经“大成”的LLM chatbot生成自定义数据集。而为了大量的生产包括但不限于<code>text-to-sql</code>场景的高质量数据集，我们首先需要一套完整的数据集生产框架，囊括<strong>数据生成，生成后的数据分析，数据验证，以及生成结构化的Prompt</strong>等功能</p><p>这里我基于<a target="_blank" rel="noopener" href="https://github.com/spf13/cobra">cobra</a>提供的创建类git / go tools命令行工具的能力，实现了提供一整套数据集生成能力的命令行工具<code>Prompt-Collector</code>，以下是<code>Prompt-Collector</code>的架构图：</p><p><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/05/02/202305022108836-f3a76e.png" alt="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/05/02/202305022108836-f3a76e.png"></p><h3 id="prompt-engineering"><a class="markdownIt-Anchor" href="#prompt-engineering"></a> <strong>Prompt Engineering</strong></h3><p>首先我们来看看最基本但也是最重要的数据集生成，这里的数据集生成是指通过<code>prompt</code>让GPT-3.5模拟<code>LLM instruction completion接口</code>的输入和输出来生成数据集；在这个子步骤中我们需要使用到一些<code>prompt engineering</code>的技巧来设计生成数据的方式，这里我简单介绍一些<code>prompt engineering</code>的基础内容，详细内容我会在后续文章中展开阐述：</p><ol><li><p><strong>Temperature</strong></p><p>我们可以在OpenAI的官方API文档中看到这个参数</p><p>简单来说，<strong>Temperature</strong>越低，结果就越具确定性，因为这样<code>LLM</code>更倾向于可能更高的下一个<code>token</code>；而<strong>Temperature</strong>升高可能会导致更多的随机性（换句话说也可以是更多的创造性），这实际上是在增加其他可能<code>token</code>的权重</p><p>在应用方面，我们可以对基于事实的<code>类QA任务</code>使用较低的<strong>Temperature</strong>，以确保其返回确切的事实和简洁的回答；而对于诗歌创作或其他<code>Idea型任务</code>，我们则可以选择适当地增大<strong>Temperature</strong>（其值域为0到2）以获取更多创造性的输出</p><p>我们当前获取数据集时设置为<code>0.3</code>，能够比较稳定的输出标准格式的数据并且能够输出比较多样化的Schema和Query</p><p>⚠️注意：一般来说只调整<strong>Temperature</strong>就够了，不需要和类似的另一个参数<strong>Top_p</strong>一起调整</p></li><li><p><em>zero-shot prompting / few-shot prompting</em></p><p><em>zero-shot prompting</em>指的是<code>prompt</code>中只包含直接的问题或是说明（没有任何希望它完成的任务的示例或演示）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;Question&gt;? &#x2F; &lt;Instruction&gt;</span><br></pre></td></tr></table></figure><p>相对应的，<em>few-shot prompting</em>指的是提供少量希望LLM输出的示例，如经典的QA格式:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Q: &lt;Question&gt;?</span><br><span class="line">A: &lt;Answer&gt;</span><br><span class="line">Q: &lt;Question&gt;?</span><br><span class="line">A: &lt;Answer&gt;</span><br><span class="line">Q: &lt;Question&gt;?</span><br><span class="line">A: &lt;Answer&gt;</span><br><span class="line">Q: &lt;Question&gt;?</span><br><span class="line">A:</span><br></pre></td></tr></table></figure></li><li><p>更具体的，我们可以拆解一下我们的<code>prompt</code>构成：</p><ul><li><strong>Instruction</strong> - 希望模型执行的特定任务或指令（如：“生成一份建表语句”，”将指定text翻译成中文“）</li><li><strong>Context</strong> - 可能涉及外部信息或其他上下文，帮助模型理解输入和输出的关系，以引导模型做出更好的响应（如QA示例）</li><li><strong>Input Data</strong> - 我们有兴趣找到答案的输入/具体问题（与<strong>Instruction</strong>对应，如：”使用该语句建的表至少包含3列“， ”Hello!“）</li><li><strong>Output Indicator</strong> - 指示输出的类型或格式（如邮件格式 / 指明字段的<code>JSON Format</code>等）</li></ul><p>基于以上构成，我们就可以具体描述大部分任务，并指示<code>LLM</code>更有效地返回内容，当然，也不是所有问题都需要这完整的四部分，仅仅一条简短的<strong>Instruction</strong>也可以收获到高质量的<code>response</code></p></li></ol><p>基于上面提到过的<code>prompt</code>构建技巧和框架，最终我们就可以得出一个比较有效的<code>prompt</code>了，如以下是我在获取针对<code>clickhouse</code>数据源的<code>text-to-sql</code>数据集时初步使用的一个<code>prompt</code>：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">## Instruction</span></span><br><span class="line">Generate a dataset</span><br><span class="line"><span class="section">## Input Data</span></span><br><span class="line">Give me %d specific cases of Clickhouse high-performance query scenarios, it should be returned in a List.</span><br><span class="line">Every case item contains 3 fields, field &quot;schema&quot; is the table structure(CREATE TABLE SQL), field &quot;question&quot; is the natural language question, and field &quot;query&quot; is the SQL query for the question.</span><br><span class="line">The query need to include a combination of the following Clickhouse capabilities:</span><br><span class="line"><span class="code">	a. Clickhouse functions like rank、dense_rank,、row_number、stochasticLogisticRegression、evalMLMethod、stochasticLinearRegression、arrayPopBack、arrayPopFront、arrayPushBack、arrayPushFront、arrayResize、arraySlice、arrayJoin、arrayDifference、arrayDistinct、tumble、hop、tumbleStart等Time Window、L1Norm、L2Norm、LinfNorm</span></span><br><span class="line"><span class="code">	b. Use Aggregate functions such as group by, ROLL UP, CUBE, etc.</span></span><br><span class="line"><span class="code">	c. Use Where and Pre Where to filter time, product, etc.</span></span><br><span class="line"><span class="code">	d. Use select syntax such as With, Sample, OFFSET, LIMIT, etc.</span></span><br><span class="line"><span class="code">	e. You can build complex scenarios with multiple with clauses / sub queries</span></span><br><span class="line"><span class="code">	f. Please make sure it is the best in terms of performance</span></span><br><span class="line"><span class="code">## Output Indicator</span></span><br><span class="line"><span class="code">Pure JSON Format string with no quotes, no explanations, no self-reference, no apologies, just answer.</span></span><br><span class="line"><span class="code">For example, this is a dataset contains 2 cases:</span></span><br><span class="line"><span class="code">` ``` `</span></span><br><span class="line"><span class="code">[</span></span><br><span class="line"><span class="code">	&#123;</span></span><br><span class="line"><span class="code">		&quot;schema&quot;: &quot;CREATE TABLE IF NOT EXISTS product_recommendation_model( customer_id UInt32, recommendation Array(UInt32), PRIMARY KEY (customer_id)) ENGINE = MergeTree() ORDER BY customer_id;&quot;,</span></span><br><span class="line"><span class="code">		&quot;question&quot;: &quot;Recommend 5 products with similar purchase history to customer 123.&quot;,</span></span><br><span class="line"><span class="code">		&quot;query&quot;: &quot;WITH( SELECT customer_id, recommendation, row_number() OVER ( ORDER BY L2Norm(recommendation) DESC) AS row_num FROM ( SELECT customer_id, arrayMap( (i, score) -&gt; IF(score &gt; 0.5, i, 0), arrayEnumerate(predictor) ) AS recommendationFROM customer_product_stateWHERE date &gt;= &#x27;2022-01-01&#x27; AND date &lt;= &#x27;2022-02-01&#x27; AND customer_id = 123 ) GROUP BY customer_id, recommendation ) AS recommendation_ranksINSERT INTO product_recommendation_model (customer_id, recommendation) SELECT customer_id, recommendationFROM recommendation_ranksWHERE row_num &lt;= 5;&quot;</span></span><br><span class="line"><span class="code">	&#125;,</span></span><br><span class="line"><span class="code">	&#123;</span></span><br><span class="line"><span class="code">    &quot;schema&quot;: &quot;CREATE OR REPLACE TABLE hits(WatchID BIGINT, JavaEnable SMALLINT, Title TEXT, GoodEvent SMALLINT, EventTime TIMESTAMP, EventDate Date, CounterID INTEGER, ClientIP INTEGER, RegionID INTEGER, UserID BIGINT, CounterClass SMALLINT, OS SMALLINT, UserAgent SMALLINT, URL TEXT, Referer TEXT, IsRefresh SMALLINT, RefererCategoryID SMALLINT, RefererRegionID INTEGER, URLCategoryID SMALLINT, URLRegionID INTEGER, ResolutionWidth SMALLINT, ResolutionHeight SMALLINT, ResolutionDepth SMALLINT, FlashMajor SMALLINT, FlashMinor SMALLINT, FlashMinor2 TEXT, NetMajor SMALLINT, NetMinor SMALLINT, UserAgentMajor SMALLINT, UserAgentMinor VARCHAR(255), CookieEnable SMALLINT, JavascriptEnable SMALLINT, IsMobile SMALLINT, MobilePhone SMALLINT, MobilePhoneModel TEXT, Params TEXT, IPNetworkID INTEGER, TraficSourceID SMALLINT, SearchEngineID SMALLINT, SearchPhrase TEXT, AdvEngineID SMALLINT, IsArtifical SMALLINT, WindowClientWidth SMALLINT, WindowClientHeight SMALLINT, ClientTimeZone SMALLINT, ClientEventTime TIMESTAMP, SilverlightVersion1 SMALLINT, SilverlightVersion2 SMALLINT, SilverlightVersion3 INTEGER, SilverlightVersion4 SMALLINT, PageCharset TEXT, CodeVersion INTEGER, IsLink SMALLINT, IsDownload SMALLINT, IsNotBounce SMALLINT, FUniqID BIGINT, OriginalURL TEXT, HID INTEGER, IsOldCounter SMALLINT, IsEvent SMALLINT, IsParameter SMALLINT, DontCountHits SMALLINT, WithHash SMALLINT, HitColor CHAR, LocalEventTime TIMESTAMP, Age SMALLINT, Sex SMALLINT, Income SMALLINT, Interests SMALLINT, Robotness SMALLINT, RemoteIP INTEGER, WindowName INTEGER, OpenerName INTEGER, HistoryLength SMALLINT, BrowserLanguage TEXT, BrowserCountry TEXT, SocialNetwork TEXT, SocialAction TEXT, HTTPError SMALLINT, SendTiming INTEGER, DNSTiming INTEGER, ConnectTiming INTEGER, ResponseStartTiming INTEGER, ResponseEndTiming INTEGER, FetchTiming INTEGER, SocialSourceNetworkID SMALLINT, SocialSourcePage TEXT, ParamPrice BIGINT, ParamOrderID TEXT, ParamCurrency TEXT, ParamCurrencyID SMALLINT, OpenstatServiceName TEXT, OpenstatCampaignID TEXT, OpenstatAdID TEXT, OpenstatSourceID TEXT, UTMSource TEXT, UTMMedium TEXT, UTMCampaign TEXT, UTMContent TEXT, UTMTerm TEXT, FromTag TEXT, HasGCLID SMALLINT, RefererHash BIGINT, URLHash BIGINT, CLID INTEGER) ENGINE = MergeTree() ORDER BY (CounterID, EventDate, UserID, EventTime, WatchID)&quot;,</span></span><br><span class="line"><span class="code">    &quot;question&quot;: &quot;give me page view count bucketed by date and order by date between 2013-07-14 and 2013-07-15 where CounterID is 62 and is not refreshed&quot;,</span></span><br><span class="line"><span class="code">    &quot;query&quot;: &quot;SELECT DATE_TRUNC(&#x27;day&#x27;, EventTime) AS M, COUNT(*) AS PageViews FROM hits WHERE CounterID = 62 AND EventDate &gt;= &#x27;2013-07-14&#x27; AND EventDate &lt;= &#x27;2013-07-15&#x27; AND IsRefresh = 0 GROUP BY DATE_TRUNC(&#x27;day&#x27;, EventTime) ORDER BY DATE_TRUNC(&#x27;day&#x27;, EventTime)&quot;</span></span><br><span class="line"><span class="code">  &#125;</span></span><br><span class="line"><span class="code">]</span></span><br><span class="line"><span class="code">` ``` `</span></span><br></pre></td></tr></table></figure><p>这个版本的<code>prompt</code>包含了<strong>Instruction, Input Data 以及 Output Indicator</strong>，在能够保证输出格式稳定为<code>pure JSON</code>的同时，也能比较好的覆盖到全部的<code>clickhouse</code>函数使用场景，且在后续的<code>Validate</code>中达到较高的留存率</p><p>当然，<code>prompt</code>构建是一个迭代过程，需要进行大量试验才能获得有效且稳定的结果，这并不是一蹴而就的；这份<code>prompt</code>在后续也被我拆解成了成更简单的子任务<code>prompt</code>，并针对其返回结果进行持续优化。在<code>prompt</code>构建的初期并不建议写大段的prompt，而是应该从简单的<code>prompt</code>开始，不断添加更多的元素和上下文，以获得更好的结果，其实很多简单的<code>prompt</code>也能收获很好的高质量<code>response</code></p><p>而当我们有一个涉及许多不同子任务的大型任务时，我们可以试着把任务分解成更简单的子任务（分步骤 / 分问题），分别完成逐步的<code>prompt</code>构建，不断积累；在子任务都能获取到稳定的<code>response</code>后，再尝试合并；这就避免了在项目前期给<code>prompt</code>设计过程增加太多的复杂性</p><p>其余的一些<code>prompt</code>设计的技巧和注意事项我会在另一篇<code>Prompt-Engineering</code>的专题文章中介绍，这里不继续展开</p><h3 id="request-openai-api"><a class="markdownIt-Anchor" href="#request-openai-api"></a> <strong>Request OpenAI API</strong></h3><p>准备好生产<code>text-to-sql dataset</code>的<code>prompt</code>后，我们就需要真正地调用<code>OpenAI API</code>生产数据集了，这里我们使用<a target="_blank" rel="noopener" href="http://github.com/sashabaranov/go-openai">go-openai</a>管理OpenAI client以及调用API</p><p>首先初始化Client：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">client := openai.NewClient(token)</span><br></pre></td></tr></table></figure><p>client初始化完成后，设置好model, messages, maxToken以及temperature(上面介绍过的关键参数，这里设置为0.3)，调用其<code>CreateChatCompletion</code>方法即可：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Create a new instance of the CompletionRequest struct</span></span><br><span class="line"><span class="comment">// Set up the chat parameters(&lt;https://platform.openai.com/docs/api-reference/completions&gt;)</span></span><br><span class="line">params := openai.ChatCompletionRequest&#123;</span><br><span class="line">	Model: openai.GPT3Dot5Turbo,</span><br><span class="line">	Messages: <span class="built_in">append</span>(messages, openai.ChatCompletionMessage&#123;</span><br><span class="line">		Role:    openai.ChatMessageRoleUser,</span><br><span class="line">		Content: newPrompt,</span><br><span class="line">	&#125;),</span><br><span class="line">	MaxTokens:   DefaultMaxTokens,</span><br><span class="line">	Temperature: DefaultTemperature,</span><br><span class="line">&#125;</span><br><span class="line">response, err = client.CreateChatCompletion(ctx, params)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">	err = fmt.Errorf(<span class="string">&quot;[Chat] failed to create chat completion: %w&quot;</span>, err)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>成功拿到<code>response</code>后，即可直接从<code>response.Choices[0].Message.Content</code>获取到返回的内容，再进行进一步解析（同时我们还可以从<code>resp.Usage.TotalTokens</code>获取到该次请求消耗的<code>token</code>数）</p><p>在进行实际请求时，我们还需要处理以下两种异常情况：</p><ul><li><p><strong>429 Rate Limit</strong></p><p><code>OpenAI</code>的API都有请求频率限制（<a target="_blank" rel="noopener" href="https://platform.openai.com/docs/guides/rate-limits">官方文档</a>），尤其是<code>Free Granted API Key</code>的<code>Rate Limit</code>，目前为<strong>3次每分钟</strong>，见下图，RPM指每分钟请求限制，TPM指每分钟token限制），而我们的token池包含了部分免费token（压低总体成本以及填充其它key的Rate Limit）；基于这种现状我就需要构建一个限制对应频率的OpenAI client池来访问OpenAI API</p><p><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/05/03/202305030124133-1d26b7.png" alt="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/05/03/202305030124133-1d26b7.png"></p></li><li><p><strong>504 Gateway Timeout</strong></p><p>我们的token池中还包括了部分<code>OpenAI</code>代理服务token，虽然代理服务解决了大陆地区访问<code>OpenAI API</code>导致封号的问题，但由于代理服务器的稳定性等问题，也会出现偶现的504，这时可以进行简单的重试，也可以在重试一定次数无果后更换为非代理client进行访问</p></li></ul><p>完成了异常请求的处理后，我们就可以稳定的获取数据了</p><p>这里我们前期选择使用<code>jsonl</code>格式直接存储数据（一行是一份数据），方便生成数据时<strong>并发写入文件</strong>，以及在<strong>超时控制 / 异常处理</strong>时可以直接中断任务上传结果数据集文件到构件 / 仓库等</p><p>至此我们成功从<code>GPT-3.5-turbo</code>拿到了想要的<code>text-to-sql dataset</code>，但为了保证生成数据的质量，我们还需要对数据进行校验</p><h3 id="数据校验"><a class="markdownIt-Anchor" href="#数据校验"></a> <strong>数据校验</strong></h3><p>获得<code>GPT-3.5</code>生成的数据之后，无疑我们仍然需要进行严格的数据校验</p><p>在<code>text-to-sql</code>模型中，常见的数据错误包括但不限于问题理解歧义、缺失信息、语言表述不准确、甚至更严重的<strong>SQL无法执行</strong>等问题。为了避免这些问题，在构建文本到SQL数据集时，应该尽可能地消除这些数据错误，以确保训练出来的模型表现最佳</p><p><strong>而在这些问题中，我们可以通过自动化校验消除SQL无法执行的错误</strong></p><p>一份 AI-SQL 训练数据结构如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> (</span><br><span class="line">	AiSQLData <span class="keyword">struct</span> &#123;</span><br><span class="line">		Datasource <span class="keyword">string</span> <span class="string">`json:&quot;datasource&quot;`</span></span><br><span class="line"></span><br><span class="line">		<span class="comment">// input part of text-to-sql model</span></span><br><span class="line">		Question <span class="keyword">string</span> <span class="string">`json:&quot;question&quot;`</span></span><br><span class="line">		Schema   <span class="keyword">string</span> <span class="string">`json:&quot;schema&quot;`</span></span><br><span class="line"></span><br><span class="line">		<span class="comment">// output part of text-to-sql model</span></span><br><span class="line">		AiSQLOutput</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	AiSQLOutput <span class="keyword">struct</span> &#123;</span><br><span class="line">		Query    <span class="keyword">string</span>  <span class="string">`json:&quot;query&quot;`</span></span><br><span class="line">		Analysis <span class="keyword">string</span>  <span class="string">`json:&quot;analysis&quot;`</span></span><br><span class="line">		Table    [][]any <span class="string">`json:&quot;table&quot;`</span></span><br><span class="line">	&#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>数据校验分为以下几个步骤：</p><ol><li><p>连接到<code>Datasource</code>对应的数据库</p></li><li><p>根据<code>Schema</code>建表</p><p>这一步中，需要将Schema和Query中的表名加上uuid以避免在校验过程中遇到重名表（为了保证<code>thread-safe</code>）</p></li><li><p>执行一次全字段的空查询以获取所有列信息，通过<code>ColumnType, 反射</code>等获取到对应<code>Golang</code>基础类型的零值使用<code>gofakeit</code>库<code>mock</code>对应<code>Golang</code>基础类型的值，构建<code>SQL</code>后执行插入对应表；这里需要注意的是，在步骤3中获取到的「对应<code>Golang</code>基础类型」可能并不能在<code>mock</code>后再次插入数据库（由于数据库列类型和<code>golang</code>类型并不是1:1的关系），所以我们需要针对诸如<code>date, smallInt, id, jsonp</code>等类型编写<code>mock</code>逻辑</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> &lt;table_name&gt; <span class="keyword">LIMIT</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><p><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/05/04/202305041449784-b16f1b.png" alt="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/05/04/202305041449784-b16f1b.png"></p><p>并且部分类型需要限制值域范围，如time和smallInt等，以精确适配数据库类型的值域范围</p></li><li><p>执行<code>Query</code></p></li></ol><p>2, 3, 4, 5步骤均可能出现错误，3中的错误可忽略，其它步骤全部执行通过则确认该数据校验通过，同时收集返回结果以便做后续的面板展示</p><h3 id="sql分析"><a class="markdownIt-Anchor" href="#sql分析"></a> <strong>SQL分析</strong></h3><p>除了针对问题和<code>schema</code>获取到执行的<code>Query</code>，在这样的问题背景下，我们还希望了解得到这样的<code>Query</code>的具体思路，以支持<a target="_blank" rel="noopener" href="https://km.woa.com/articles/show/576525">ABP</a>调优中的【<a target="_blank" rel="noopener" href="https://km.woa.com/articles/show/576525#%E7%AC%AC%E4%B8%89%E6%AC%A1%E8%B0%83%E4%BC%98-%E5%AD%A6%E4%B9%A0%E5%A4%8D%E6%9D%82%E5%87%BD%E6%95%B0%E9%97%AE%E9%A2%98">学习复杂函数问题</a>】这一项，代替原来的基于<code>llama_index</code>构建复杂函数文档的方案</p><p>首先我们可以直接从<code>Query</code>中解析出全部用到的函数（在完成上述数据校验的<strong>步骤5</strong>校验后），并根据提前收集好的各数据源函数集合找到其对应功能（这样在利于<code>LLM</code>推理分析的同时，生成的数据也将在训练时把各数据源的函数信息喂给<code>LLM</code>，一举两得），以此为基础构建<code>prompt</code>:</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">## Instruction</span></span><br><span class="line">Show me the steps to get the provided Query</span><br><span class="line"><span class="section">## Context</span></span><br><span class="line">I&#x27;ve got a Query SQL based on a schema(CREATE TABLE SQL) and a specific task</span><br><span class="line"><span class="section">## Input Data</span></span><br><span class="line">schema: &quot;CREATE OR REPLACE TABLE hits(WatchID BIGINT, JavaEnable SMALLINT, Title TEXT, GoodEvent SMALLINT, EventTime TIMESTAMP, EventDate Date, CounterID INTEGER, ClientIP INTEGER, RegionID INTEGER, UserID BIGINT, CounterClass SMALLINT, OS SMALLINT, UserAgent SMALLINT, URL TEXT, Referer TEXT, IsRefresh SMALLINT, RefererCategoryID SMALLINT, RefererRegionID INTEGER, URLCategoryID SMALLINT, URLRegionID INTEGER, ResolutionWidth SMALLINT, ResolutionHeight SMALLINT, ResolutionDepth SMALLINT, FlashMajor SMALLINT, FlashMinor SMALLINT, FlashMinor2 TEXT, NetMajor SMALLINT, NetMinor SMALLINT, UserAgentMajor SMALLINT, UserAgentMinor VARCHAR(255), CookieEnable SMALLINT, JavascriptEnable SMALLINT, IsMobile SMALLINT, MobilePhone SMALLINT, MobilePhoneModel TEXT, Params TEXT, IPNetworkID INTEGER, TraficSourceID SMALLINT, SearchEngineID SMALLINT, SearchPhrase TEXT, AdvEngineID SMALLINT, IsArtifical SMALLINT, WindowClientWidth SMALLINT, WindowClientHeight SMALLINT, ClientTimeZone SMALLINT, ClientEventTime TIMESTAMP, SilverlightVersion1 SMALLINT, SilverlightVersion2 SMALLINT, SilverlightVersion3 INTEGER, SilverlightVersion4 SMALLINT, PageCharset TEXT, CodeVersion INTEGER, IsLink SMALLINT, IsDownload SMALLINT, IsNotBounce SMALLINT, FUniqID BIGINT, OriginalURL TEXT, HID INTEGER, IsOldCounter SMALLINT, IsEvent SMALLINT, IsParameter SMALLINT, DontCountHits SMALLINT, WithHash SMALLINT, HitColor CHAR, LocalEventTime TIMESTAMP, Age SMALLINT, Sex SMALLINT, Income SMALLINT, Interests SMALLINT, Robotness SMALLINT, RemoteIP INTEGER, WindowName INTEGER, OpenerName INTEGER, HistoryLength SMALLINT, BrowserLanguage TEXT, BrowserCountry TEXT, SocialNetwork TEXT, SocialAction TEXT, HTTPError SMALLINT, SendTiming INTEGER, DNSTiming INTEGER, ConnectTiming INTEGER, ResponseStartTiming INTEGER, ResponseEndTiming INTEGER, FetchTiming INTEGER, SocialSourceNetworkID SMALLINT, SocialSourcePage TEXT, ParamPrice BIGINT, ParamOrderID TEXT, ParamCurrency TEXT, ParamCurrencyID SMALLINT, OpenstatServiceName TEXT, OpenstatCampaignID TEXT, OpenstatAdID TEXT, OpenstatSourceID TEXT, UTMSource TEXT, UTMMedium TEXT, UTMCampaign TEXT, UTMContent TEXT, UTMTerm TEXT, FromTag TEXT, HasGCLID SMALLINT, RefererHash BIGINT, URLHash BIGINT, CLID INTEGER) ENGINE = MergeTree() ORDER BY (CounterID, EventDate, UserID, EventTime, WatchID)&quot;</span><br><span class="line">question: &quot;give me page view count bucketed by date and order by date between 2013-07-14 and 2013-07-15 where CounterID is 62 and is not refreshed&quot;</span><br><span class="line">query: &quot;SELECT DATE<span class="emphasis">_TRUNC(&#x27;day&#x27;, EventTime) AS M, COUNT(*) AS PageViews FROM hits WHERE CounterID = 62 AND EventDate &gt;= &#x27;2013-07-14&#x27; AND EventDate &lt;= &#x27;2013-07-15&#x27; AND IsRefresh = 0 GROUP BY DATE_</span>TRUNC(&#x27;day&#x27;, EventTime) ORDER BY DATE<span class="emphasis">_TRUNC(&#x27;day&#x27;, EventTime)</span></span><br><span class="line"><span class="emphasis">used_</span>functions: </span><br><span class="line">[&#123;</span><br><span class="line"><span class="code">	&quot;func_name&quot;: &quot;date_trunc&quot;,</span></span><br><span class="line"><span class="code">	&quot;feature&quot;: &quot;Truncates a date to a specified precision&quot;</span></span><br><span class="line"><span class="code">&#125;, &#123;</span></span><br><span class="line"><span class="code">	&quot;func_name&quot;: &quot;count&quot;,</span></span><br><span class="line"><span class="code">	&quot;feature&quot;: &quot;Counts the number of rows or not-NULL values&quot;</span></span><br><span class="line"><span class="code">&#125;]</span></span><br><span class="line"><span class="code">Solve by breaking the problem into steps. First, Analyze the question; second, understand the schema and bind the question; third, write the Query, and then explain why we used the functions</span></span><br><span class="line"><span class="code">## Output Indicator</span></span><br><span class="line"><span class="code">` ``` `</span></span><br><span class="line"><span class="code">## Step 1: Analyze the Question</span></span><br><span class="line"><span class="code">...</span></span><br><span class="line"><span class="code">## Step 2: Understand the Schema</span></span><br><span class="line"><span class="code">...</span></span><br><span class="line"><span class="code">## Step 3: Write the SQL Query</span></span><br><span class="line"><span class="code">...</span></span><br><span class="line"><span class="code">## Step 4: Explanation of Functions Used</span></span><br><span class="line"><span class="code">...</span></span><br><span class="line"><span class="code">` ``` `</span></span><br></pre></td></tr></table></figure><p>值得注意的是，这里我使用了<code>CoT</code>(Chain-of-Thought)的<code>prompt</code>构建技巧，即<code>Input Data</code>部分的最后一句话：</p><blockquote><p>Solve by breaking the problem into steps. First, Analyze the question; second, understand the schema and bind the question; third, write the Query, and then explain why we used the functions</p></blockquote><p><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/04/20/202304201403527-b58820.png" alt="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/04/20/202304201403527-b58820.png"></p><p>对于目前的<code>LLM</code>来说，如今最困难的任务之一可能是需要某种形式的推理；而使用<code>CoT</code>提示就可以通过中间推理步骤，让<code>LLM</code>实现复杂的推理能力，有关<code>CoT</code>的具体内容我会在另一篇<code>Prompt-Engineering</code>的专题文章中介绍</p><p>最终该prompt可以实现这样的效果：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">## Step 1: Analyze the Question</span></span><br><span class="line"></span><br><span class="line">The question requires us to retrieve the page view count from a table called &quot;hits&quot; that has several columns. We need to filter the data by CounterID, date, and IsRefresh column. Finally, the query should group the data by the day and order it by the date.</span><br><span class="line"></span><br><span class="line"><span class="section">## Step 2: Understand the Schema</span></span><br><span class="line"></span><br><span class="line">The schema defines a table called &quot;hits&quot; with many columns that store information about the website visitors, their actions, and their devices. Each row represents a single event, and the table is sorted by CounterID, EventDate, UserID, EventTime, WatchID. The columns that are relevant to our query are:</span><br><span class="line"></span><br><span class="line"><span class="bullet">-</span> EventTime: the timestamp of the event</span><br><span class="line"><span class="bullet">-</span> CounterID: the ID of the counter that tracks the event</span><br><span class="line"><span class="bullet">-</span> IsRefresh: a flag that indicates whether the event was triggered by a page refresh</span><br><span class="line"><span class="bullet">-</span> EventDate: the date of the event</span><br><span class="line"></span><br><span class="line"><span class="section">## Step 3: Write the SQL Query</span></span><br><span class="line"></span><br><span class="line">Based on the above analysis, we can write the SQL query as follows:</span><br><span class="line"></span><br><span class="line"><span class="code">` `</span><span class="code">`` `</span></span><br><span class="line">SELECT DATE<span class="emphasis">_TRUNC(&#x27;day&#x27;, EventTime) AS M, COUNT(*) AS PageViews</span></span><br><span class="line"><span class="emphasis">FROM hits</span></span><br><span class="line"><span class="emphasis">WHERE CounterID = 62</span></span><br><span class="line"><span class="emphasis">  AND EventDate &gt;= &#x27;2013-07-14&#x27;</span></span><br><span class="line"><span class="emphasis">  AND EventDate &lt;= &#x27;2013-07-15&#x27;</span></span><br><span class="line"><span class="emphasis">  AND IsRefresh = 0</span></span><br><span class="line"><span class="emphasis">GROUP BY DATE_</span>TRUNC(&#x27;day&#x27;, EventTime)</span><br><span class="line">ORDER BY DATE<span class="emphasis">_TRUNC(&#x27;day&#x27;, EventTime)</span></span><br><span class="line"><span class="emphasis">` ``` `</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">## Step 4: Explanation of Functions Used</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">We used the following functions in our query:</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">- `DATE_</span>TRUNC`: This function truncates a timestamp to a specified time unit (in our case, day) and returns a new timestamp. We use it to group the data by day.</span><br><span class="line"><span class="bullet">-</span> <span class="code">`COUNT`</span>: This function counts the number of rows in each group. We use it to count the number of page views in each day.</span><br><span class="line"></span><br><span class="line">Both functions are common in SQL queries and are used to manipulate and summarize data.</span><br></pre></td></tr></table></figure><p>有了这样的<code>CoT</code>链<code>prompt</code>，不仅能够让<code>LLM</code>明白各个函数的具体功能，也能为<code>LLM</code>提供<code>text-to-sql</code>问题的推导思路，以实现一些复杂查询的推导；这一部分的分析也可以考虑移到数据校验之前，与数据生成的部分做一个整合，这样补充<code>Analysis</code>信息后的数据集也经过了验证，最终模型在问题理解能力和<code>SQL</code>推理能力都比未添加<code>Analysis</code>信息前要好得多</p><h2 id="ci工程化"><a class="markdownIt-Anchor" href="#ci工程化"></a> <strong>CI工程化</strong></h2><p>实现了上述的基于<code>GPT-3.5</code>生成数据集以及数据校验后，我们可以通过使用<code>CI/CD pipeline</code>将数据集的构建和自动化数据校验过程结合起来，以确保我们能够快速、可靠地构建数据集并过滤掉低质量数据，同时也为后续上线使用中的反馈流程打好基础，确保我们的数据集始终处于最佳状态，并且可以随时部署到我们的模型中</p><p>基于<code>prompt-collector</code>提供的比较友好的命令行调用方式，我们可以使用下述命令直接生成和校验AI-SQL的数据集：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 可以分两步</span><br><span class="line">prompt-collector generate -c 2000 -d clickhouse -o $&#123;&#123; ci.workspace &#125;&#125;&#x2F;generated&#x2F; --concurrent 8 --timeout 3h</span><br><span class="line">prompt-collector validate --input $&#123;&#123; ci.workspace &#125;&#125;&#x2F;generated&#x2F; -o &#x2F;data&#x2F;prompt-collector&#x2F;test&#x2F;dataset&#x2F;validated --concurrent 4</span><br><span class="line"># 也支持生成数据并校验</span><br><span class="line">prompt-collector generate -c 2000 -d clickhouse -o $&#123;&#123; ci.workspace &#125;&#125;&#x2F;generated&#x2F; --validate --concurrent 8 --timeout 3h</span><br></pre></td></tr></table></figure><p>随后完成配套的流水线搭建，实现定时的数据集生成和数据集校验（这里将<code>-c</code>设置到比较高的值并将<code>--timeout</code>设置为与流水线触发周期间隔相同的时间，以实现<strong>24小时</strong>满载运行，并且<code>timeout</code>参数保证了在遇到异常情况时能及时终止并将已生成的数据及时上传和持久化）</p><p>当前开启8并发（<code>--concurrent 8</code>）的情况下，生产数据的速度可以达到<code>6400条 / h</code>，单次请求消耗如下（生产5条数据），计算可得生产每条数据消耗约为<strong>0.0004美元</strong></p><table><thead><tr><th>模型</th><th>问题消耗 Tokens</th><th>回答消耗 Tokens</th><th>总消耗 Tokens</th><th>费用（美元）</th></tr></thead><tbody><tr><td>gpt-3.5-turbo-0301</td><td>480</td><td>580</td><td>1060</td><td>0.00212</td></tr></tbody></table><p>初期可以直接在完成生成和校验后将新数据写回仓库，直接开始运行训练任务</p><p><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/04/30/202304301615550-a8c318.png" alt="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/04/30/202304301615550-a8c318.png"></p><p><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/04/30/202304301615319-8727c9.png" alt="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/04/30/202304301615319-8727c9.png"></p><p>后期可以持续的写入数据库或是其它存储介质，方便做后续的处理和使用</p><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> <strong>总结</strong></h2><p>我们可以选择直接使用开源数据集，如<code>WikiSQL、SParC、HybridSQL、CoSQL</code>等的数据集，也可以使用基于GPT-3.5生成的数据集（在一些开源数据集匮乏的场景下吗，如<code>clickhouse</code>复杂查询的<code>text-to-sql</code>数据），在基于GPT-3.5生成数据集时也就需要使用<code>prompt engineering</code>的技巧来提高生成数据集的效率和质量，并不断迭代更新结构化的<code>prompt</code>，以支持和实现<code>CoT</code>链等特性</p><p>在获取数据后，我们还需要进行严格的数据校验，以确保我们构建的<code>text-to-sql</code>数据集是高质量的；除此之外，我们还需要进行SQL分析，以了解SQL的具体思路，将思路也融合进训练数据集中，提升其问题理解能力和SQL推理能力，以支持其构建更加复杂的查询</p><p>最后，我们可以使用CI实现自动化构建数据集，以持续支持我们的模型训练及反馈流程等，最终实现全自动炼丹的一整套框架</p></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者:</span> <span class="post-copyright-info"><a href="mailto:undefined">Kevinello</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接:</span> <span class="post-copyright-info"><a href="http://kevinello.ltd/2023/07/06/%E5%A6%82%E4%BD%95%E4%B8%BA%E7%A7%81%E6%9C%89%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BF%AB%E9%80%9F%E6%B2%89%E6%B7%80%E9%AB%98%E8%B4%A8%E9%87%8F%E6%95%B0%E6%8D%AE%E9%9B%86/">http://kevinello.ltd/2023/07/06/如何为私有大语言模型快速沉淀高质量数据集/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明:</span> <span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://kevinello.ltd" target="_blank">Kevinello</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/LLM/">LLM</a><a class="post-meta__tags" href="/tags/Prompt-Engineering/">Prompt-Engineering</a><a class="post-meta__tags" href="/tags/OpenAI/">OpenAI</a></div><div class="post_share"><div class="social-share" data-image="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/09/07/202309071443770-70c1ed.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/09/06/LLM%E8%BF%9C%E4%B8%8D%E4%BB%85%E4%BB%85%E6%98%AFChat%20Model%E2%80%94%E2%80%94LangChain%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E4%B8%8E%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/"><img class="prev-cover" src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/09/07/202309071425723-3c7e69.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">LLM远不仅仅是Chat Model——LangChain基本概念与使用示例</div></div></a></div><div class="next-post pull-right"><a href="/2023/03/05/Redis%E6%80%A7%E8%83%BD%E4%B9%8B%E5%B7%85%EF%BC%9A%E5%BB%B6%E8%BF%9F%E9%97%AE%E9%A2%98%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"><img class="next-cover" src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/02/28/202302281707283-c5d6b1.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Redis性能之巅：延迟问题排障指南</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/09/06/LLM%E8%BF%9C%E4%B8%8D%E4%BB%85%E4%BB%85%E6%98%AFChat%20Model%E2%80%94%E2%80%94LangChain%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E4%B8%8E%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/" title="LLM远不仅仅是Chat Model——LangChain基本概念与使用示例"><img class="cover" src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/09/07/202309071425723-3c7e69.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-06</div><div class="title">LLM远不仅仅是Chat Model——LangChain基本概念与使用示例</div></div></a></div></div></div><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i> <span>评论</span></div><div id="comment-switch"><span class="first-comment">Utterances</span><span class="switch-btn"></span><span class="second-comment">Twikoo</span></div></div><div class="comment-wrap"><div><div id="utterances-wrap"></div></div><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2022/04/11/myself-e3fde6.png" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">Kevinello</div><div class="author-info__description"></div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">50</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">95</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/kevinello"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/kevinello" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://space.bilibili.com/23149976" target="_blank" title="Bilibili"><i class="iconfont icon-bilibili-fill"></i></a><a class="social-icon" href="mailto:kevinello42@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9C%80%E8%A6%81%E4%BA%86%E8%A7%A3%E7%9A%84%E8%AF%8D"><span class="toc-number">2.</span> <span class="toc-text">需要了解的词</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.</span> <span class="toc-text">开源数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#prompt-collector"><span class="toc-number">4.</span> <span class="toc-text">Prompt-Collector</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#prompt-engineering"><span class="toc-number">4.1.</span> <span class="toc-text">Prompt Engineering</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#request-openai-api"><span class="toc-number">4.2.</span> <span class="toc-text">Request OpenAI API</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%A0%A1%E9%AA%8C"><span class="toc-number">4.3.</span> <span class="toc-text">数据校验</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sql%E5%88%86%E6%9E%90"><span class="toc-number">4.4.</span> <span class="toc-text">SQL分析</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ci%E5%B7%A5%E7%A8%8B%E5%8C%96"><span class="toc-number">5.</span> <span class="toc-text">CI工程化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">6.</span> <span class="toc-text">总结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/09/06/LLM%E8%BF%9C%E4%B8%8D%E4%BB%85%E4%BB%85%E6%98%AFChat%20Model%E2%80%94%E2%80%94LangChain%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E4%B8%8E%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/" title="LLM远不仅仅是Chat Model——LangChain基本概念与使用示例"><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/09/07/202309071425723-3c7e69.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="LLM远不仅仅是Chat Model——LangChain基本概念与使用示例"></a><div class="content"><a class="title" href="/2023/09/06/LLM%E8%BF%9C%E4%B8%8D%E4%BB%85%E4%BB%85%E6%98%AFChat%20Model%E2%80%94%E2%80%94LangChain%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E4%B8%8E%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/" title="LLM远不仅仅是Chat Model——LangChain基本概念与使用示例">LLM远不仅仅是Chat Model——LangChain基本概念与使用示例</a><time datetime="2023-09-05T16:08:35.000Z" title="发表于 2023-09-06 00:08:35">2023-09-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/07/06/%E5%A6%82%E4%BD%95%E4%B8%BA%E7%A7%81%E6%9C%89%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BF%AB%E9%80%9F%E6%B2%89%E6%B7%80%E9%AB%98%E8%B4%A8%E9%87%8F%E6%95%B0%E6%8D%AE%E9%9B%86/" title="如何为私有大语言模型快速沉淀高质量数据集"><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/09/07/202309071443770-70c1ed.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="如何为私有大语言模型快速沉淀高质量数据集"></a><div class="content"><a class="title" href="/2023/07/06/%E5%A6%82%E4%BD%95%E4%B8%BA%E7%A7%81%E6%9C%89%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BF%AB%E9%80%9F%E6%B2%89%E6%B7%80%E9%AB%98%E8%B4%A8%E9%87%8F%E6%95%B0%E6%8D%AE%E9%9B%86/" title="如何为私有大语言模型快速沉淀高质量数据集">如何为私有大语言模型快速沉淀高质量数据集</a><time datetime="2023-07-05T16:08:35.000Z" title="发表于 2023-07-06 00:08:35">2023-07-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/05/Redis%E6%80%A7%E8%83%BD%E4%B9%8B%E5%B7%85%EF%BC%9A%E5%BB%B6%E8%BF%9F%E9%97%AE%E9%A2%98%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/" title="Redis性能之巅：延迟问题排障指南"><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/02/28/202302281707283-c5d6b1.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Redis性能之巅：延迟问题排障指南"></a><div class="content"><a class="title" href="/2023/03/05/Redis%E6%80%A7%E8%83%BD%E4%B9%8B%E5%B7%85%EF%BC%9A%E5%BB%B6%E8%BF%9F%E9%97%AE%E9%A2%98%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/" title="Redis性能之巅：延迟问题排障指南">Redis性能之巅：延迟问题排障指南</a><time datetime="2023-03-05T09:08:07.000Z" title="发表于 2023-03-05 17:08:07">2023-03-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/05/clash-on-linux%E9%85%8D%E7%BD%AE/" title="clash-on-linux配置"><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/03/05/202303051704184-34cc7e.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="clash-on-linux配置"></a><div class="content"><a class="title" href="/2023/03/05/clash-on-linux%E9%85%8D%E7%BD%AE/" title="clash-on-linux配置">clash-on-linux配置</a><time datetime="2023-03-05T07:34:11.000Z" title="发表于 2023-03-05 15:34:11">2023-03-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/02/28/%5Bvscode%20issue%5D%20Golang%20Debug%20%E6%97%A0%E6%B3%95%E5%91%BD%E4%B8%AD%E6%96%AD%E7%82%B9/" title="\[vscode issue\] Golang Debug 无法命中断点"><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/02/28/202302281702991-ae1947.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="\[vscode issue\] Golang Debug 无法命中断点"></a><div class="content"><a class="title" href="/2023/02/28/%5Bvscode%20issue%5D%20Golang%20Debug%20%E6%97%A0%E6%B3%95%E5%91%BD%E4%B8%AD%E6%96%AD%E7%82%B9/" title="\[vscode issue\] Golang Debug 无法命中断点">\[vscode issue\] Golang Debug 无法命中断点</a><time datetime="2023-02-28T09:15:07.000Z" title="发表于 2023-02-28 17:15:07">2023-02-28</time></div></div></div></div></div></div></main><footer id="footer" style="background-image:url(https://kevinello-1302687393.file.myqcloud.com/picgo/2023/09/07/202309071443770-70c1ed.png)"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Kevinello</div><div class="framework-info"><span>框架</span> <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题</span> <a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">🥳 🥳 🥳 🥳 🥳</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Algolia</span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script><script src="/js/search/optimized_algolia.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>function loadUtterances () {
  let ele = document.createElement('script')
  ele.setAttribute('id', 'utterances_comment')
  ele.setAttribute('src', 'https://utteranc.es/client.js')
  ele.setAttribute('repo', 'Kevinello/gitalk')
  ele.setAttribute('issue-term', 'pathname')
  let nowTheme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'photon-dark' : 'github-light'
  ele.setAttribute('theme', nowTheme)
  ele.setAttribute('crossorigin', 'anonymous')
  ele.setAttribute('async', 'true')
  document.getElementById('utterances-wrap').insertAdjacentElement('afterbegin',ele)
}

function utterancesTheme () {
  const iframe = document.querySelector('.utterances-frame')
  if (iframe) {
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'photon-dark' : 'github-light'
    const message = {
      type: 'set-theme',
      theme: theme
    };
    iframe.contentWindow.postMessage(message, 'https://utteranc.es');
  }
}

if ('Utterances' === 'Utterances' || !false) {
  if (false) btf.loadComment(document.getElementById('utterances-wrap'), loadUtterances)
  else loadUtterances()
} else {
  function loadOtherComment () {
    loadUtterances()
  }
}</script><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'blog-comments-9gil6as164013b6c',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.vemoji)'))
      }
    }, null))
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-comments-9gil6as164013b6c',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      document.getElementById('twikoo-count').innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runFn)
  }

  if ('Utterances' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>