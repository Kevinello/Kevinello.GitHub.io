<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>Redis性能之巅：延迟问题排障指南 | Kevinello</title><meta name="keywords" content="数据库,性能优化,Redis,监控"><meta name="author" content="Kevinello"><meta name="copyright" content="Kevinello"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="前言 在 Redis 的实际使用过程中，我们经常会面对以下的场景：  在 Redis 上执行同样的命令，为什么有时响应很快，有时却很慢 为什么 Redis 执行 GET、SET、DEL 命令耗时也很久 为什么我的 Redis 突然慢了一波，之后又恢复正常了 为什么我的 Redis 稳定运行了很久，突然从某个时间点开始变慢了  这时我们还是需要一个全面的排障流程，不能无厘头地进行优化；全面的排障流"><meta property="og:type" content="article"><meta property="og:title" content="Redis性能之巅：延迟问题排障指南"><meta property="og:url" content="http://kevinello.ltd/2023/03/05/Redis%E6%80%A7%E8%83%BD%E4%B9%8B%E5%B7%85%EF%BC%9A%E5%BB%B6%E8%BF%9F%E9%97%AE%E9%A2%98%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/index.html"><meta property="og:site_name" content="Kevinello"><meta property="og:description" content="前言 在 Redis 的实际使用过程中，我们经常会面对以下的场景：  在 Redis 上执行同样的命令，为什么有时响应很快，有时却很慢 为什么 Redis 执行 GET、SET、DEL 命令耗时也很久 为什么我的 Redis 突然慢了一波，之后又恢复正常了 为什么我的 Redis 稳定运行了很久，突然从某个时间点开始变慢了  这时我们还是需要一个全面的排障流程，不能无厘头地进行优化；全面的排障流"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/02/28/202302281707283-c5d6b1.png"><meta property="article:published_time" content="2023-03-05T09:08:07.000Z"><meta property="article:modified_time" content="2023-03-04T19:23:18.696Z"><meta property="article:author" content="Kevinello"><meta property="article:tag" content="数据库"><meta property="article:tag" content="性能优化"><meta property="article:tag" content="Redis"><meta property="article:tag" content="监控"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/02/28/202302281707283-c5d6b1.png"><link rel="shortcut icon" href="/imgs/K.jpg"><link rel="canonical" href="http://kevinello.ltd/2023/03/05/Redis%E6%80%A7%E8%83%BD%E4%B9%8B%E5%B7%85%EF%BC%9A%E5%BB%B6%E8%BF%9F%E9%97%AE%E9%A2%98%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload='this.media="all"'><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?d2a20aecba22b2eaf60183c4831d9a52";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-RV8K5FBVX5"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-RV8K5FBVX5")</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"13UJR6CRNO","apiKey":"456e56f51ec27a1e13d67bef144f6747","indexName":"Kevinello_blog","hits":{"per_page":6},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容：${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: {"limitDay":180,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"Redis性能之巅：延迟问题排障指南",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2023-03-05 03:23:18"}</script><noscript><style>#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="//at.alicdn.com/t/font_2232093_k6128tldgy.css"><meta name="generator" content="Hexo 5.2.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2022/04/11/myself-e3fde6.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">51</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">97</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(https://kevinello-1302687393.file.myqcloud.com/picgo/2023/02/28/202302281707283-c5d6b1.png)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Kevinello</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i> <span>搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i> <span>About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Redis性能之巅：延迟问题排障指南</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-03-05T09:08:07.000Z" title="发表于 2023-03-05 17:08:07">2023-03-05</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-03-04T19:23:18.696Z" title="更新于 2023-03-05 03:23:18">2023-03-05</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/">技术文章</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">13k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>44分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="Redis性能之巅：延迟问题排障指南"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h1><p>在 Redis 的实际使用过程中，我们经常会面对以下的场景：</p><ul><li>在 Redis 上执行同样的命令，为什么有时响应很快，有时却很慢</li><li>为什么 Redis 执行 GET、SET、DEL 命令耗时也很久</li><li>为什么我的 Redis 突然慢了一波，之后又恢复正常了</li><li>为什么我的 Redis 稳定运行了很久，突然从某个时间点开始变慢了</li></ul><p>这时我们还是需要一个<strong>全面</strong>的排障流程，不能无厘头地进行优化；全面的排障流程可以帮助我们找到真正的根因和性能瓶颈，以及实施正确高效的优化方案</p><p>这篇文章我们就从可能导致 Redis 延迟的方方面面开始，逐步深入排障深水区，以提供一个「<strong>全面</strong>」的 Redis 延迟问题排查思路</p><h1 id="需要了解的词"><a class="markdownIt-Anchor" href="#需要了解的词"></a> 需要了解的词</h1><ul><li><p><strong>Copy On Write</strong><br><code>COW</code> 是一种建立在虚拟内存重映射技术之上的技术，因此它需要 <code>MMU</code> 的硬件支持，<code>MMU</code> 会记录当前哪些内存页被标记成只读，当有进程尝试往这些内存页中写数据的时候，<code>MMU</code> 就会抛一个异常给操作系统内核，内核处理该异常时为该进程分配一份物理内存并复制数据到此内存地址，重新向 <code>MMU</code> 发出执行该进程的写操作</p><p><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2022/11/27/DbUc7vDX0AAm9n6-7d5ec2.jpeg" alt="https://kevinello-1302687393.file.myqcloud.com/picgo/2022/11/27/DbUc7vDX0AAm9n6-7d5ec2.jpeg"></p></li><li><p><strong>内存碎片</strong><br>操作系统负责为每个进程分配物理内存，而操作系统中的虚拟内存管理器保管着由内存分配器分配的实际内存映射</p><p>如果我们的应用程序需求<code>1GB</code>大小的内存，内存分配器将首先尝试找到一个<strong>连续的内存段</strong>来存储数据；如果找不到连续的段，则分配器必须将进程的<strong>数据分成多个段</strong>，从而导致内存开销增加</p></li><li><p><strong>SWAP</strong><br>顾名思义，当某进程向OS请求内存发现不足时，OS会把内存中暂时不用的数据交换出去，放在<code>SWAP分区</code>中，这个过程称为**<code>SWAP OUT</code>；当某进程又需要这些数据且OS发现还有空闲物理内存时，又会把<code>SWAP分区</code>中的数据交换回物理内存中，这个过程称为<code>SWAP IN</code>，详情可参考<a target="_blank" rel="noopener" href="https://draveness.me/whys-the-design-linux-swapping/">这篇文章</a></p><p><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/03/05/202303050251548-068652.png" alt="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/03/05/202303050251548-068652.png"></p></li><li><p><strong>redis 监控指标</strong><br>合理完善的监控指标无疑能大大助力我们的排障，本篇文章中提到了很多的 redis 监控指标，详情可以参考这篇文章： <a target="_blank" rel="noopener" href="https://www.notion.so/redis-8f3630c6312c40549de429f98d3337e7">redis监控指标</a></p></li></ul><h1 id="排除无关原因"><a class="markdownIt-Anchor" href="#排除无关原因"></a> <strong>排除无关原因</strong></h1><p>当我们发现从我们的业务服务发起请求到接收到<code>Redis</code>的回包这条链路慢时，我们需要先排除其它的一些无关<code>Redis</code>自身的原因，如：</p><ul><li><p>业务自身准备请求耗时过长</p></li><li><p>业务服务器到 <code>Redis</code> 服务器之间的网络存在问题，例如网络线路质量不佳，网络数据包在传输时存在延迟、丢包等情况</p><p>💡 网络和通信导致的固有延迟</p><p>客户端使用TCP/IP连接或Unix域连接连接到Redis。1 Gbit/s网络的典型延迟约为200 us，而Unix域套接字的延迟可低至30 us。这实际上取决于您的网络和系统硬件。在通信本身之上，系统增加了一些更多的延迟(由于线程调度、CPU缓存、NUMA放置等)。在虚拟环境中，系统引起的延迟比在物理机上高得多</p><p>结果是，即使Redis在亚微秒范围内处理大多数命令，执行多次往返到服务器的客户端也必须为这些与网络和系统相关的延迟买单</p></li><li><p><code>Redis</code>实例所在的机器带宽不足 / <code>docker</code>网桥性能问题等</p></li></ul><p>排障事大，但咱也不能冤枉了<code>Redis</code>；首先我们还是应该把其它因素都排除完了，再把焦点关注在业务服务到 <code>Redis</code> 这条链路上</p><p>如以下的火焰图就可以很肯定的说问题出现在 Redis 上了：</p><p><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2022/11/20/image-20221120142243271-01d0c4.png" alt="https://kevinello-1302687393.file.myqcloud.com/picgo/2022/11/20/image-20221120142243271-01d0c4.png"></p><p>在排除无关因素后，如何确认 Redis 是否真的变慢了？</p><h2 id="测试流程"><a class="markdownIt-Anchor" href="#测试流程"></a> <strong>测试流程</strong></h2><p>排除无关因素后，我们可以按照以下基本步骤来判断某一 Redis 实例是否变慢了:</p><ol><li>监控并记录一个相对正常的 Redis 实例（相对低负载、key 存储结构简单合理、连接数未满）的相关指标</li><li>找到认为表现不符合预期的 Redis 实例（如使用该实例后业务接口明显变慢），在<strong>相同配置的服务器</strong>上监控并记录这个实例的相关指标</li><li>若表现不符合预期的 Redis 实例的相关指标明显达不到正常 Redis 实例的标准（<strong>延迟</strong>两倍以上、<code>OPS</code> 仅为正常实例的 1/3、<strong>内存碎片率</strong>较高等），即可认为这个 Redis 实例的指标未达到预期</li></ol><p>确认是 Redis 实例的某些指标未达到预期后，我们就可以开始逐步分析拆解可能导致 Redis 表现不佳的因素，并确认优化方案了</p><h1 id="快速清单"><a class="markdownIt-Anchor" href="#快速清单"></a> 快速清单</h1><blockquote><p><strong>I’ve little time, give me the checklist</strong></p></blockquote><p>在线上发生故障时，我们都没有那么多时间去深究原因，所以在深入到排障的深水区前，我们可以先从最影响最大的一些问题开始检查，这里是一份「会对<code>redis</code>基本运行造成严重影响的问题」的 <code>checklist</code>：</p><ul><li>确保没有运行阻塞服务器的缓慢命令；使用 Redis 的**<a target="_blank" rel="noopener" href="https://redis.io/commands/slowlog">耗时命令记录</a>**功能来检查这一点</li><li>对于EC2用户，请确保使用基于<code>HVM</code>的现代EC2实例，如<code>m3.dium</code> 等，否则，<code>fork()</code>系统调用带来的延迟太大了</li><li>禁用透明内存大页。使用<code>echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</code>来禁用它们，然后重新启动Redis进程</li><li>如果使用的是虚拟机，则可能存在与 Redis 本身无关的固有延迟；使用**<code>redis-cli --intrinsic-latency 100</code>**检查延迟，确认该延迟是否符合预期（注意：您需要在服务器上而不是在客户机上运行此命令）</li><li>启用并使用 <a target="_blank" rel="noopener" href="https://redis.io/docs/management/optimization/latency-monitor/">Redis 的延迟监控功能</a>，更好的监控 Redis 实例中的延迟事件和原因</li></ul><h1 id="导致redis-latency的具体原因"><a class="markdownIt-Anchor" href="#导致redis-latency的具体原因"></a> <strong>导致Redis Latency的具体原因</strong></h1><p>如果使用我们的快速清单并不能解决实际的延迟问题，我们就得深入 redis 性能排障的深水区，多方面逐步深究其中的具体原因了</p><h3 id="使用复杂度过高的命令-大型命令"><a class="markdownIt-Anchor" href="#使用复杂度过高的命令-大型命令"></a> 使用复杂度过高的命令 / 「大型」命令</h3><p>要找到这样的命令执行记录，需要使用 Redis 提供的<strong>耗时命令</strong>统计的功能，查看 Redis 耗时命令之前，我们需要先在<code>redis.conf</code>中设置耗时命令的阈值；如：设置耗时命令的阈值为 5ms，保留近 500 条耗时命令记录：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># The following time is expressed in microseconds, so 1000000 is equivalent</span><br><span class="line"># to one second. Note that a negative number disables the slow log, while</span><br><span class="line"># a value of zero forces the logging of every command.</span><br><span class="line">slowlog-log-slower-than 10000</span><br><span class="line"></span><br><span class="line"># There is no limit to this length. Just be aware that it will consume memory.</span><br><span class="line"># You can reclaim memory used by the slow log with SLOWLOG RESET.</span><br><span class="line">slowlog-max-len 128</span><br></pre></td></tr></table></figure><p>或是直接在<code>redis-cli</code>中使用<code>CONFIG</code>命令配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 命令执行耗时超过 5 毫秒，记录耗时命令</span><br><span class="line">CONFIG SET slowlog-log-slower-than 5000</span><br><span class="line"># 只保留最近 500 条耗时命令</span><br><span class="line">CONFIG SET slowlog-max-len 500</span><br></pre></td></tr></table></figure><p>通过查看<strong>耗时命令记录</strong>，我们就可以知道在什么时间点，执行了哪些比较耗时的命令</p><p>如果应用程序执行的 Redis 命令有以下特点，那么有可能会导致操作延迟变大：</p><ol><li>经常使用 O(N) 以上复杂度的命令，例如 SORT, SUNION, ZUNIONSTORE 等聚合类命令</li><li>使用 O(N) 复杂度的命令，但 N 的值非常大</li></ol><p>第一种情况导致变慢的原因是 Redis 在操作内存数据时，时间复杂度过高，要花费更多的 CPU 资源</p><p>第二种情况导致变慢的原因是 处理**「大型」redis 命令（大请求包体 / 大返回包体的redis请求）**，对于这样的命令来说，虽然其只有两次内核态与用户态的上下文切换，但由于redis是单线程处理回调事件的，所以后续请求很有可能被这一个大型请求阻塞，这时可能需要考虑<code>业务请求拆解</code> 尽量分批执行，以保证redis服务的稳定性</p><h3 id="bigkey"><a class="markdownIt-Anchor" href="#bigkey"></a> Bigkey</h3><p>bigkey 一般指包含大量数据或大量成员和列表的 key，如下所示就是一些典型的 bigkey（根据Redis的实际用例和业务场景，bigkey 的定义可能会有所不同）：</p><ul><li>value 大小为 5 MB(数据太大)的 <code>String</code></li><li>包含 20000 个元素的<code>List</code>(列表中的元素数量过多)</li><li>有 10000 个成员的<code>ZSET</code>密钥(成员数量过多)</li><li>一个大小为 100 MB的<code>Hash key</code>，即便只包含 1000 个成员(key太大)</li></ul><p>在上一节的耗时命令查询中，如果我们发现榜首并不是复杂度过高的命令，而是 SET / DEL 等简单命令，这很有可能就是 <strong>redis 实例中存在 bigkey</strong> 导致的</p><p>💡 bigkey 会导致包括但不限于以下的问题：</p><ul><li>Redis 的内存使用量不断增长，最终导致实例 <code>OOM</code>，或者因为达到最大内存限制而导致写入被阻塞和重要 key 被驱逐</li><li>访问偏差导致的资源倾斜，<strong>bigkey</strong> 的存在可能会导致某个 Redis 实例达到性能瓶颈，从而导致整个集群也达到性能瓶颈；在这种情况下，Redis 集群中一个节点的内存使用量通常会因为对 <strong>bigkey</strong> 的访问需求而远远超过其他节点，而 Redis 集群中数据迁移时有一个最小粒度，这意味着该节点上的 bigkey 占用的内存无法进行 balance</li><li>由于将 bigkey 请求从 socket 读取到 Redis 占用了几乎所有带宽，Redis 的其它请求都会受到影响</li><li>删除BigKey时，由于主库长时间阻塞（释放 bigkey 占用的内存）导致同步中断或主从切换</li></ul><p>💡 如何定位 bigkey</p><ol><li><p>使用redis-cli 提供的<code>—-bigkeys</code> 参数<br><code>redis-cli</code>提供了扫描 bigkey 的 option <code>—-bigkeys</code>，执行以下命令就可以扫描 redis 实例中 bigkey 的分布情况，以 key 类型维度输出结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ redis-cli -h 127.0.0.1 -p 6379 --bigkeys -i 0.01</span><br><span class="line">[00.00%] Biggest string found so far</span><br><span class="line">...</span><br><span class="line">[98.23%] Biggest string found so far</span><br><span class="line">-------- summary -------</span><br><span class="line"></span><br><span class="line">Sampled 829675 keys <span class="keyword">in</span> the keyspace!</span><br><span class="line">Total key length <span class="keyword">in</span> bytes is 10059825 (avg len 12.13)</span><br><span class="line"></span><br><span class="line">Biggest string found <span class="string">&#x27;key:291880&#x27;</span> has 10 bytes</span><br><span class="line">Biggest   list found <span class="string">&#x27;mylist:004&#x27;</span> has 40 items</span><br><span class="line">Biggest    <span class="built_in">set</span> found <span class="string">&#x27;myset:2386&#x27;</span> has 38 members</span><br><span class="line">Biggest   <span class="built_in">hash</span> found <span class="string">&#x27;myhash:3574&#x27;</span> has 37 fields</span><br><span class="line">Biggest   zset found <span class="string">&#x27;myzset:2704&#x27;</span> has 42 members</span><br><span class="line"></span><br><span class="line">36313 strings with 363130 bytes (04.38% of keys, avg size 10.00)</span><br><span class="line">787393 lists with 896540 items (94.90% of keys, avg size 1.14)</span><br><span class="line">1994 sets with 40052 members (00.24% of keys, avg size 20.09)</span><br><span class="line">1990 hashs with 39632 fields (00.24% of keys, avg size 19.92)</span><br><span class="line">1985 zsets with 39750 members (00.24% of keys, avg size 20.03)</span><br></pre></td></tr></table></figure><p>从输出结果我们可以很清晰地看到，每种数据类型所占用的最大内存 / 拥有最多元素的 key 是哪一个，以及每种数据类型在整个实例中的占比和平均大小 / 元素数量</p><p><strong>bigkey 扫描</strong>实际上是 Redis 执行了 SCAN 命令，遍历整个实例中所有的 key，然后针对 key 的类型，分别执行 <strong><code>STRLEN, LLEN, HLEN, SCARD和ZCARD</code></strong> 命令，来获取 String 类型的长度，容器类型（List, Hash, Set, ZSet）的元素个数</p><p>💡 ⚠️NOTICE: 当执行 bigkey 扫描时，要注意 2 个问题：</p><ol><li>对线上实例进行 bigkey 扫描时，Redis 的 OPS 会突增，为了降低扫描过程中对 Redis 的影响，最好控制一下扫描的频率，指定 <code>-i</code> 参数即可，它表示扫描过程中每次扫描后休息的时间间隔(秒)</li><li>扫描结果中，对于容器类型（List, Hash, Set, ZSet）的 key，只能扫描出元素最多的 key；但一个 key 的元素多，不一定表示内存占用也多，我们还需要根据业务情况，进一步评估内存占用情况</li></ol><p>以下是<strong>bigkey 扫描</strong>实际用到的命令的时间复杂度：</p><p><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/02/20/202302201501688-3ba54f.png" alt="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/02/20/202302201501688-3ba54f.png"></p></li><li><p>使用开源的 <strong><a target="_blank" rel="noopener" href="https://github.com/sripathikrishnan/redis-rdb-tools">redis-rdb-tools</a></strong><br>通过 <code>redis-rdb-Tools</code>，我们可以根据自己的标准准确分析 Redis 实例中所有密钥的实际内存使用情况，同时它还可以避免中断在线服务，分析完成后，您可以获得简洁、易于理解的报告<br><code>redis-rdb-Tools</code>对<code>rdb</code>文件的分析是离线的，对在线的 redis 服务没有影响；这无疑是它对比第一种方案最大的优势，但也正是因为是离线分析，其分析结果的实时性可能达不到某些场景下的标准，对大型<code>rdb</code>文件的分析可能需要较长的时间</p></li></ol><p>💡 针对 bigkey 问题的优化措施</p><ol><li>上游业务应避免在不合适的场景写入 bigkey（夸张一点：用<code>String</code>存储大型<code>binary file</code>），如必须使用，可以考虑进行<code>大key拆分</code> ，如：对于 string 类型的 Bigkey，可以考虑拆分成多个 key-value；对于 hash 或者 list 类型，可以考虑拆分成多个 hash 或者 list</li><li>定期清理<code>HASH key</code>中的无效数据（使用<code>HSCAN</code>和<code>HDEL</code>），避免<code>HASH key</code>中的成员持续增加带来的 bigkey 问题</li><li><strong>Redis ≥ 4.0</strong>中，用 <strong><code>UNLINK</code></strong> 命令替代 <strong><code>DEL</code></strong>，此命令可以把释放 key 内存的操作，放到后台线程中去执行，从而降低对 Redis 的影响</li><li><strong>Redis ≥ 6.0</strong>中，可以开启 lazy-free 机制(<code>lazyfree-lazy-user-del = yes</code>)，在执行 DEL 命令时，释放内存也会放到后台线程中执行</li><li>针对消息队列 / 生产消费场景的 List, Set 等，设置过期时间或实现定期清理任务，并配置相关监控以及时处理突发情况（如线上流量暴增，下有服务无法消费等产生的消费积压）</li></ol><p>即便我们有一系列的解决方案，我们也要尽量避免在实例中存入 bigkey</p><p>这是因为 bigkey 在很多场景下，依旧会产生性能问题；例如，bigkey 在分片集群模式下，对于数据的迁移也会有性能影响；以及资源倾斜、数据过期、数据淘汰、透明大页等，都会受到 bigkey 的影响</p><h3 id="hotkey"><a class="markdownIt-Anchor" href="#hotkey"></a> Hotkey</h3><p>在讨论 bigkey 时，我们也经常谈到 hotkey ，当访问某个密钥的工作量明显高于其他密钥时，我们可以称之为 hotkey；以下就是一些 hotkey 的例子：</p><ul><li>在一个 QPS 10w 的 Redis 实例中，只有一个 key 的 QPS 达到了 7000 次</li><li>拥有数千个成员、总大小为1MB的哈希键每秒会收到大量的HGETALL请求(在这种情况下，我们将其称为热键，因为访问一个键比访问其他键消耗的带宽要大得多)</li><li>拥有数万个 member 的 ZSET 每秒处理大量的 ZRANGE 请求(<code>cpu时间</code>明显高于用于其他 key 请求的<code>cpu时间</code>。同样，我们可以说这种消耗大量CPU的Key就是HotKey)</li></ul><p>💡 hotkey 通常会带来以下的问题：</p><ul><li>hotkey 会导致较高的 CPU 负载，并影响其它请求的处理</li><li>资源倾斜，对 hotkey 的请求会集中在个别 Redis 节点/机器上，而不是<code>shard</code>到不同的 Redis 节点上，导致<strong>内存/CPU负载</strong>集中在这个别的节点上，Redis 集群利用率不能达到预期</li><li>hotkey 上的流量可能在流量高峰时突然飙升，导致 redis CPU 满载甚至缓存服务崩溃，在缓存场景下导致缓存雪崩，大量的请求会直接命中其它较慢的数据源，最终导致业务不可用等不可接受的后果</li></ul><p>💡 如何定位 hotkey</p><ol><li><p>使用<code>redis-cli</code>提供的<code>—hotkeys</code>参数<br>Redis 从<strong>4.0</strong>版本开始在<code>redis-cli</code>中提供 hotkey 参数，以方便实例粒度的 hotkey 分析；它可以返回所有 key 被访问的次数，但需要先将<code>maxmemory policy</code>设置为<code>allkey-LFU</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Scanning the entire keyspace to find hot keys as well as</span></span><br><span class="line"><span class="comment"># average sizes per key type.  You can use -i 0.1 to sleep 0.1 sec</span></span><br><span class="line"><span class="comment"># per 100 SCAN commands (not usually needed).</span></span><br><span class="line"></span><br><span class="line">Error: ERR An LFU maxmemory policy is not selected, access frequency not tracked. Please note that when switching between policies at runtime LRU and LFU data will take some time to adjust.</span><br></pre></td></tr></table></figure></li><li><p>使用<code>monitor</code>命令<br>Redis 的<code>monitor</code>命令可以实时输出 Redis 接收到的所有请求，包括<strong>访问时间、客户端IP、命令和key</strong>；我们可以短时间执行monitor命令，并将输出重定向到文件；结束后，可以通过对文件中的请求进行分类和分析来找到这段时间的 hotkey</p><p>💡 <code>monitor</code>命令会消耗大量CPU、内存和网络资源；因此，对于本身就负载较大的 Redis 实例来说，<code>monitor</code>命令可能会让性能问题进一步恶化；同时，这种异步采集分析方案的时效性较差，分析的准确性依赖于<code>monitor</code>命令的执行时长；因此，在大多数无法长时间执行该命令的在线场景中，结果的准确性并不好</p></li><li><p>上游服务针对 redis 请求进行监控<br>所有的 redis 请求都来自于上游服务，上游服务可以在上报时进行相关的指标监控、汇总及分析，以定位 hotkey ；但这样的方式需要上游服务支持，并不独立</p></li></ol><p>💡 针对 hotkey 问题的优化方案</p><ol><li><p><strong>使用 <code>pipeline</code></strong><br>在一些非实时的 bigkey 请求场景下，我们可以使用 <code>pipeline</code> 来大幅度降低 Redis 实例的 CPU 负载<br>首先我们要知道，Redis 核心的工作负荷是一个单线程在处理，这里指的是——<strong>网络 IO</strong> 和<strong>命令执行</strong>是由一个线程来完成的；而 <strong>Redis 6.0 中引入了多线程</strong>，在 <strong>Redis 6.0</strong> 之前，从网络 IO 处理到实际的读写命令处理都是由单个线程完成的，但随着网络硬件的性能提升，Redis 的性能瓶颈有可能会出现在<strong>网络 IO 的处理</strong>上，也就是说<strong>单个主线程处理网络请求的速度跟不上底层网络硬件的速度</strong>。针对此问题，Redis 采用多个 IO 线程来处理网络请求，提高网络请求处理的并行度，但多 IO 线程只用于处理网络请求，<strong>对于命令处理，Redis 仍然使用单线程处理</strong></p><p>而 <strong>Redis 6.0 以前的</strong>单线程网络 IO 模型的处理具体的负载在哪里呢？虽然 Redis 利用<code>epoll</code>机制实现 IO 多路复用（即使用<code>epoll</code>监听各类事件，通过事件回调函数进行事件处理），但 <strong>I/O 这一步骤是无法避免且始终由单线程串行处理的</strong>，且涉及用户态/内核态的切换，即：</p><ul><li>从<code>socket</code>中读取请求数据，会从内核态将数据拷贝到用户态 （<code>read</code>调用）</li><li>将数据回写到<code>socket</code>，会将数据从用户态拷贝到内核态 （<code>write</code>调用）</li></ul><p><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/02/19/image-20230219170911819-894557.png" alt="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/02/19/image-20230219170911819-894557.png"></p><p>高频简单命令请求下，用户态/内核态的切换带来的开销被更加放大，最终会导致<code>redis-server</code> <code>cpu</code>满载→<code>redis-server</code> <code>OPS</code>不及预期→上游服务海量请求超时→最终造成类似<strong>缓存穿透</strong>的结果，这时我们就可以使用<code>pipeline</code>来处理这样的场景了</p><p>💡 <a target="_blank" rel="noopener" href="https://redis.io/docs/manual/pipelining/"><strong>redis pipeline</strong></a></p><p>众所周知，<code>redis pipeline</code>可以让<code>redis-server</code>一次接收一组指令（在内核态中存入输入缓冲区，收到客户端的<code>Exec</code>指令再调用<code>read() syscall</code>）后再执行，减少<code>I/O</code>(即<code>accept -&gt; read -&gt; write</code>)次数，在<strong>高频可聚合命令</strong>的场景下使用<code>pipeline</code>可以大大减少<code>socket I/O</code>带来的<strong>内核态与用户态之间的上下文切换开销</strong></p><p>下面我们进行跑一组基于<code>golang redis</code>客户端的简单高频命令的<code>Benchmark</code>测试（不使用<code>pipeline</code>和使用<code>pipeline</code>对比），同时使用<a target="_blank" rel="noopener" href="https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/attaching-perf-stat-to-a-running-process_counting-events-during-process-execution-with-perf-stat">perf</a>对 Redis 4 实例监控上下文切换次数：</p><ul><li><p><strong>Set without Pipeline(redis 4.0.14)</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">perf <span class="built_in">stat</span> -p 15537 -e context-switches -a sleep 10</span><br><span class="line"></span><br><span class="line"> Performance counter stats <span class="keyword">for</span> process id <span class="string">&#x27;15537&#x27;</span>:</span><br><span class="line"></span><br><span class="line">            96,301      context-switches</span><br><span class="line"></span><br><span class="line">      10.001575750 seconds time elapsed</span><br></pre></td></tr></table></figure></li><li><p><strong>Set using Pipeline(redis 4.0.14)</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">perf <span class="built_in">stat</span> -p 15537 -e context-switches -a sleep 10</span><br><span class="line"></span><br><span class="line"> Performance counter stats <span class="keyword">for</span> process id <span class="string">&#x27;15537&#x27;</span>:</span><br><span class="line"></span><br><span class="line">                17      context-switches</span><br><span class="line"></span><br><span class="line">      10.001722488 seconds time elapsed</span><br></pre></td></tr></table></figure></li></ul><p>可以看到在不使用<code>pipeline</code>执行高频简单命令时产生了大量的上下文切换，这无疑会占用大量的<code>cpu时间</code></p><p>另一方面，<code>pipeline</code>虽然好用，但是每次<code>pipeline</code>组装的命令个数不能没有节制，否则一次组装<code>pipeline</code>数据量过大，一方面会增加客户端的等待时间，另一方面会造成一定的网络阻塞，可以将一次包含大量命令的<code>pipeline</code>拆分成多次较小的<code>pipeline</code>来完成，比如可以将<code>pipeline</code>的总发送大小控制在内核输入输出缓冲区大小之内（内核的输入输出缓冲区大小一般是4K-8K，在不同操作系统中有所差异，可配置修改），同时控制在<strong>单个 TCP 报文最大值1460字节</strong>之内</p><blockquote><p>最大传输单元（MTU — Maximum Transmission Unit）在以太网中的最大值是<strong>1500字节</strong>，扣减20个字节的<code>IP</code>头和20个字节的<code>TCP</code>头，即<strong>1460字节</strong></p></blockquote></li><li><p><strong>MemCache</strong><br>当 hotkey 本身可预估，且总大小可控时，我们可以考虑使用<code>MemCache</code>直接存储</p><ul><li>省去了 Redis 接入</li><li>直接的内存读取，保证高性能</li><li>摆脱带宽限制</li></ul><p>但同时它也带来了新的问题：</p><ul><li>在像<code>k8s</code>这样的高可用多实例架构下，多<code>pod</code> 间的同步以及和原始数据库的同步是一个大问题，很有可能导致<strong>脏读</strong></li><li>同样是在多实例的情况下，会带来很多的内存浪费</li></ul><p>同时 MemCache 相比于 Redis 也少了很多 feature ，可能不能满足业务需求</p><table><thead><tr><th>Feature</th><th>Redis</th><th>MemCache</th></tr></thead><tbody><tr><td>原生支持不同的数据结构</td><td>✅</td><td>❌</td></tr><tr><td>原生支持持久化</td><td>✅</td><td>❌</td></tr><tr><td>横向扩展(replication)</td><td>✅</td><td>❌</td></tr><tr><td>聚合操作</td><td>✅</td><td>❌</td></tr><tr><td>支持高并发</td><td>✅</td><td>✅</td></tr></tbody></table></li><li><p>Redis 读写分离<br>当对 hotkey 的请求仅仅集中在读上时，我们可以考虑读写分离的 Redis 集群方案（很多公有云厂商都有提供），针对 hotkey 的读请求，新增<code>read-only replica</code>来承担读流量，原<code>replica</code>作为热备不提供服务，如下图所示（链式复制架构）：</p><p><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/02/21/202302211546876-135607.png" alt="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/02/21/202302211546876-135607.png"></p><p>这里我们不展开讲读写分离的其它优势，仅针对读多写少的业务场景来说，使用读写分离的 Redis 提供了更多的选择，业务可以根据场景选择最适合的规格，充分利用每一个<code>read-only replica</code>的资源，且读写分离架构还有比较好的横向扩容能力、客户端友好等优势</p><table><thead><tr><th>规格</th><th>QPS</th><th>带宽</th></tr></thead><tbody><tr><td>1 master</td><td>8-10万读写</td><td>10-48 MB</td></tr><tr><td>1 master + 1 read-only replica</td><td>10万写 + 10万读</td><td>20-64 MB</td></tr><tr><td>1 master + 3 read-only replica</td><td>10万写 + 30万读</td><td>40-128 MB</td></tr><tr><td>n * master + m * read-only replica</td><td>n * 100,000 write + m * 100,000 read</td><td>10(m+n) MB - 32(m+n) MB</td></tr></tbody></table><p>当然我们也不能忽略读写分离架构的缺点，在有大量写请求的场景中，读写分离架构将不可避免地产生延迟，这很有可能造成脏读，所以读写分离架构不适用于读写负载都较高以及实时性要求较高的场景</p></li></ol><h3 id="key集中过期"><a class="markdownIt-Anchor" href="#key集中过期"></a> Key集中过期</h3><p>当 Redis 实例表现出的现象是：周期性地在一个小的时间段出现一波延迟高峰时，我们就需要 check 一下是否有大批量的 key 集中过期；那么为什么 key 集中过期会导致 Redis 延迟变大呢？</p><p>我们首先来了解一下 Redis 的过期策略是怎样的</p><p>Redis 处理过期 key 的方式有两种——<strong>被动方式和主动方式</strong></p><p>💡 <strong>被动方式</strong></p><p><code>key</code> 过期的时候不删除，每次从 Redis 获取<code>key</code>时检查是否过期，若过期，则删除，返回<code>null</code></p><p>优点：删除操作只发生在从数据库取出key的时候发生，而且只删除当前<code>key</code>，所以对CPU时间的占用是比较少的</p><p>缺点：若大量的<code>key</code>在超出超时时间后，很久一段时间内，都没有被获取过，此时的无效缓存是永久暂用在内存中的，那么可能发生内存泄露（无效<code>key</code>占用了大量的内存）</p><p>💡 <strong>主动方式</strong></p><p>Redis 每<code>100ms</code>执行以下步骤：</p><ol><li>抽样检查附加了<code>TTL</code>的20个随机<code>key</code>(环境变量**<code>ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP</code>，默认为20**)</li><li>删除抽样中所有过期的<code>key</code></li><li>如果超过**<code>25%</code>**的<code>key</code>过期，重复步骤1</li></ol><p>优点：通过限制删除操作的时长和频率，来限制删除操作对CPU时间的占用；同时解决**<code>被动方式</code>**中无效<code>key</code>存留的问题</p><p>缺点: 仍然可能有最高达到**<code>25%</code>的无效<code>key</code>存留**；在<code>CPU时间</code>友好方面，不如**<code>被动方式</code><strong>，主动方式会</strong>block**住主线程</p><p>难点: 需要合理设置删除操作的执行时长（每次删除执行多长时间）和执行频率（每隔多长时间做一次删除，这要根据服务器运行情况和实际需求来决定）</p><p>如果 Redis 实例配置为上面的主动方式的，当 Redis 中的 key 集中过期时，Redis 需要处理大量的过期 key；这无疑会增加 Redis 的 CPU 负载和内存使用，可能会使 Redis 变慢，特别当 Redis 实例中存在 bigkey 时，这个耗时会更久；而且这个耗时不会被记录在<code>slow log</code>中</p><p><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/02/28/redis_request-b0e5a7.png" alt="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/02/28/redis_request-b0e5a7.png"></p><p>💡 解决方案</p><p>为了避免这种情况，可以考虑以下几种方法：</p><ul><li>尽量避免 key 集中过期，如果需要批量插入key（如批量插入一批设置了同样<code>ExpireAt</code>的key），可以通过额外的小量随机过期时间来打散 key 的过期时间</li><li>在 Redis 4.0 以上的版本中提供了 lazy-free 选项，当删除过期 key 时，把释放内存的操作放到后台线程中执行，避免阻塞主线程</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lazyfree-lazy-expire yes</span><br></pre></td></tr></table></figure><p>从监控的角度出发，我们还需要建立对<code>expired_keys</code>的实时监控和突增告警，以及时发出告警帮助我们定位到业务中的相关问题</p><h3 id="触及maxmemory"><a class="markdownIt-Anchor" href="#触及maxmemory"></a> 触及maxmemory</h3><p>当我们的 Redis 实例达到了设置的内存上限时，我们也会很明显地感知到 Redis 延迟增大</p><p>究其原因，当 Redis 达到 maxmemory 后，如果继续往 Redis 中写入数据，Redis 将会触发内存淘汰策略来清理一些数据以腾出内存空间，这个过程需要耗费一定的 CPU 和内存资源，如果淘汰过程中产生了大量的 Swap 交换或者内存回收，将会导致 Redis 变慢，甚至可能导致 Redis 崩溃</p><p>常见的驱逐策略有以下几种：</p><ul><li><strong>noeviction</strong>: 不删除策略，达到最大内存限制时，如果需要更多内存，直接返回错误信息；大多数写命令都会导致占用更多的内存(有极少数会例外， 如 DEL )</li><li><strong>allkeys-lru</strong>: 所有key通用; 优先删除最长时间未被使用(less recently used ，LRU) 的 key</li><li><strong>volatile-lru</strong>: 只限于设置了 expire 的部分; 优先删除最长时间未被使用(less recently used ，LRU) 的 key</li><li><strong>allkeys-random</strong>: 所有key通用; 随机删除一部分 key</li><li><strong>volatile-random</strong>: 只限于设置了 expire 的部分; 随机删除一部分 key</li><li><strong>volatile-ttl</strong>: 只限于设置了 expire 的部分; 优先删除剩余时间(time to live，TTL) 短的key</li><li><strong>volatile-lfu</strong>: <em>added in Redis 4</em>, 从设置了expire 的 key 中删除使用频率最低的 key</li><li><strong>allkeys-lfu</strong>: <em>added in Redis 4</em>, 从所有 key 中删除使用频率最低的 key</li></ul><p>最常用的驱逐策略是<code>allkeys-lru / volatile-lru</code></p><p>⚠️需要注意的是：Redis 的淘汰数据的逻辑与删除过期 key 的一样，<strong>也是在命令真正执行之前执行的</strong>，也就是说它也会增加我们操作 Redis 的延迟，并且写 OPS 越高，延迟也会越明显</p><p><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/03/01/redis_request_2-94d424.png" alt="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/03/01/redis_request_2-94d424.png"></p><p>另外，如果 Redis 实例中还存储了 bigkey，那么<strong>在淘汰删除 bigkey 释放内存时，也会耗时比较久</strong></p><p>💡 解决方案</p><p>为了避免 Redis 达到 maxmemory 后变慢，可以考虑以下几种解决方案：</p><ol><li>设置合理的 maxmemory，可以根据实际情况设置 Redis 的 maxmemory，避免 Redis 在运行过程中出现内存不足的情况（大白话就是加钱加内存）</li><li>开启 Redis 的持久化功能，以将 Redis 中的数据持久化到磁盘中，避免数据丢失，并且在 Redis 重启后可以快速地恢复加载数据</li><li>使用 Redis 的分区功能，将 Redis 中的数据分散到多个 Redis 实例中，以减轻单个 Redis 实例内存淘汰的负载压力</li><li>与删除过期key一样，针对淘汰key也可以开启<code>layz-free</code>，把淘汰 key 释放内存的操作放到后台线程中执行</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lazyfree-lazy-eviction yes</span><br></pre></td></tr></table></figure><h3 id="持久化耗时"><a class="markdownIt-Anchor" href="#持久化耗时"></a> 持久化耗时</h3><p>为了保证 Redis 数据的安全性，我们可能会开启后台定时 RDB 和 AOF rewrite 功能</p><p><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/03/01/202303010334908-e64cd8.png" alt="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/03/01/202303010334908-e64cd8.png"></p><p>而为了在后台生成<code>RDB</code>文件，或者在启用<code>AOF</code>持久化的情况下追加写只读<code>AOF</code>文件，Redis 都需要<code>fork</code>一个子进程，<code>fork</code>操作(在主线程中运行)本身可能会导致延迟</p><p>下图分别是<code>AOF持久化</code>和<code>RDB持久化</code>的流程图：</p><p><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/03/01/202303010335624-c492a0.png" alt="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/03/01/202303010335624-c492a0.png"></p><p><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/03/01/202303010337502-64d96f.png" alt="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/03/01/202303010337502-64d96f.png"></p><p>在大多数类Unix系统上，<code>fork</code>的成本都很高，因为它涉及复制与进程相关联的许多对象，尤其是与虚拟内存机制相关联的<code>**页表**</code></p><p>例如，在<code>Linux/AMD64</code>系统上，内存被划分为 <code>**4kB**</code> 的页（如不开启内存大页）；而为了将虚拟地址转换为物理地址，每个进程存储了一个页表，该页表包含该进程的地址空间每一页的至少一个指针；一个大小为<code>24 GB</code>的 Redis 实例就会需要一个<code>24 GB / 4 kB * 8 = 48 MB</code>的页表</p><p>在执行后台持久化时，就需要<code>fork</code>此实例，也就需要为页表分配和复制<code>48MB</code>的内存；这无疑会耗费大量CPU时间，特别是在部分虚拟机上，分配和初始化大内存块本身成本就更高</p><table><thead><tr><th>system</th><th>time cost</th></tr></thead><tbody><tr><td>Linux beefy VM on VMware</td><td>6.0GB RSS forked in 77 milliseconds (12.8 milliseconds / GB)</td></tr><tr><td>Linux running on physical machine (Unknown HW)</td><td>6.1GB RSS forked in 80 milliseconds (13.1 milliseconds / GB)</td></tr><tr><td>Linux running on physical machine (Xeon @ 2.27Ghz)</td><td>6.9GB RSS forked into 62 milliseconds (9 milliseconds / GB)</td></tr><tr><td>Linux VM on 6sync (KVM)</td><td>360 MB RSS forked in 8.2 milliseconds (23.3 milliseconds / GB)</td></tr><tr><td>Linux VM on EC2, old instance types (Xen)</td><td>6.1GB RSS forked in 1460 milliseconds (239.3 milliseconds / GB)</td></tr><tr><td>Linux VM on EC2, new instance types (Xen)</td><td>1GB RSS forked in 10 milliseconds (10 milliseconds / GB)</td></tr><tr><td>Linux VM on Linode (Xen)</td><td>0.9GBRSS forked into 382 milliseconds (424 milliseconds / GB)</td></tr></tbody></table><p>可以看到在<code>Xen</code>上运行的某些<code>VM</code>的<code>fork</code>耗时比在物理机上要高一个数量级到两个数量级</p><p>💡 如何查看 fork 耗时</p><p>我们可以在 <code>redis-cli</code> 上执行 INFO 命令，查看 <code>latest_fork_usec</code> 项</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">INFO latest_fork_usec</span><br><span class="line"><span class="comment"># 上一次 fork 耗时，单位为微秒</span></span><br><span class="line">latest_fork_usec:59477</span><br></pre></td></tr></table></figure><p>这个时间就是主进程在 <code>fork</code> 子进程期间，整个实例阻塞无法处理客户端请求的时间；这个时间对于大多数业务来说无疑是不能过高的（如达到秒级）</p><p>除了定时的数据持久化会生成 <code>RDB</code> 之外，当主从节点第一次建立数据同步时，主节点也会创建子进程生成 <code>RDB</code>，然后发给从节点进行一次全量同步，所以，这个过程也会对 Redis 产生性能影响</p><p>💡 解决方案</p><ol><li>更改持久化模式<br>如果Redis的持久化模式为<code>RDB</code>，我们可以尝试使用<code>AOF</code>模式来减少持久化的耗时的突增（AOF rewrite 可以是多次的追加写）</li><li>优化写入磁盘的速度<br>如果 Redis 所在的磁盘写入速度较慢，我们可以尝试将 Redis 迁移到写入速度更快的磁盘上</li><li>控制 Redis 实例的内存：<br>用作缓存的 Redis 实例尽量在 10G 以下，执行 fork 的耗时与实例大小有关，实例越大，耗时越久</li><li>避免虚拟化部署<br>Redis 实例不要部署在虚拟机上，fork 的耗时也与系统也有关，虚拟机比物理机耗时更久</li><li>合理配置数据持久化策略<br>于低峰期在 slave 节点执行 RDB 备份；而对于丢失数据不敏感的业务（例如把 Redis 当做纯缓存使用），可以关闭 AOF 和 AOF rewrite</li><li>降低主从库全量同步的概率<br>适当调大 <code>repl-backlog-size</code> 参数，避免主从全量同步</li></ol><h3 id="开启内存大页"><a class="markdownIt-Anchor" href="#开启内存大页"></a> 开启内存大页</h3><p>在上面提到的定时 RDB 和 AOF rewrite持久化功能中，除了<code>fork</code>本身带来的页表复制的耗时外，还会有<strong>内存大页</strong>带来的延迟</p><p><strong>内存页</strong>是用户应用程序向操作系统申请内存的单位，常规的内存页大小是 <code>4KB</code>，而Linux 内核从 2.6.38 开始，支持了<strong>内存大页机制</strong>，该机制允许应用程序以 <code>2MB</code> 大小为单位，向操作系统申请内存</p><p>在开启内存大页的机器上调用<code>bgsave</code> 或者 <code>bgrewriteaof</code>fork出子进程后，此时<strong>主进程依旧是可以接收写请求的</strong>，而此时处理写请求，会采用 Copy On Write（写时复制）的方式操作内存数据（两个进程共享内存大页，仅需复制一份<code>页表</code>）</p><p><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/03/01/redis_fork_COW-bc18ac.png" alt="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/03/01/redis_fork_COW-bc18ac.png"></p><p>在写负载较高的 Redis 实例中，不断处理写命令将导致命令针对几千个内存大页（哪怕只涉及一个内存大页上的一小部分数据更改），导致几乎整个进程内存的**<code>COW</code>**，这将造成这些写命令巨大的延迟，以及巨大的额外峰值内存</p><p>同样的，如果这个写请求操作的是一个 bigkey，那主进程在拷贝这个 bigkey 内存块时，涉及到的内存大页会更多，时间也会更久，<strong>十恶不赦的 bigkey</strong> 在这里又一次影响到了性能</p><p>无疑在开启<code>AOF / RDB</code>时，我们需要关闭内存大页</p><p>我们可以使用以下命令查看是否开启了内存大页：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line">[always] madvise never</span><br></pre></td></tr></table></figure><p>如果该文件的输出为 **<code>[always]</code>**或 <strong><code>[madvise]</code></strong>，则透明大页是启用的；如果输出为 <strong><code>[never]</code></strong>，则透明大页是禁用的</p><p>在Linux系统中，可以使用以下命令来关闭透明大页：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">typescriptCopy code</span><br><span class="line">echo never &gt; &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;enabled</span><br><span class="line">echo never &gt; &#x2F;sys&#x2F;kernel&#x2F;mm&#x2F;transparent_hugepage&#x2F;defrag</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>第一行命令将透明大页的使用模式设置为 <strong><code>never</code></strong>，第二行命令将透明大页的碎片整理模式设置为 <strong><code>never</code></strong>；这样就可以关闭透明大页了</p><h3 id="aof和磁盘io造成的延迟"><a class="markdownIt-Anchor" href="#aof和磁盘io造成的延迟"></a> AOF和磁盘I/O造成的延迟</h3><p>针对<code>AOF</code>(Append Only File)持久化策略来说，除了前面提到的<code>fork</code>子进程追加写文件会带来性能损耗造成延迟</p><p>首先我们来详细看一下<code>AOF</code>的实现原理，AOF基本上依赖两个<strong>系统调用</strong>来完成其工作；一个是<code>WRITE(2)</code>，用于将数据写入<code>Append Only</code>文件，另一个是<code>fDataync(2)</code>，用于刷新磁盘上的<strong>内核文件缓冲区</strong>，以确保用户指定的持久性级别，而WRITE(2)和fDatync(2)调用都可能是延迟的来源</p><p>对 <code>WRITE(2)</code> 来说，当系统范围的磁盘缓冲区同步正在进行时，或者当输出缓冲区已满并且内核需要刷新磁盘以接受新的写入时，<code>WRITE(2)</code>都会因此阻塞</p><p>对<code>fDataync(2)</code>来说情况更糟，因为使用了许多内核和文件系统的组合，我们可能需要几毫秒到几秒的时间才能完成<code>fDataync(2)</code>，特别是在某些其它进程正在执行I/O的情况下；因此，<code>Redis 2.4</code>之后版本会尽可能在另一个线程执行<code>fDataync(2)</code>调用</p><p>💡 解决方案</p><p>最直接的解决方案当然是从 redis 配置出发，那么有哪些配置会影响到这两个系统调用的执行策略呢</p><p>我们可以使用<code>appendfsync</code>配置，该配置项提供了三种磁盘缓冲区刷新策略</p><ul><li><p><strong>no</strong><br>当<code>appendfsync</code>被设置为<code>**no**</code>时，redis 不会再执行<code>fsync</code>，在这种情况下唯一的延迟来源就只有<code>WRITE(2)</code>了</p><p>但这种情况很少见，除非磁盘无法处理 Redis 接收数据的速度（不太可能），或是磁盘被其他I/O密集型进程严重减慢</p><p>这种方案对 Redis 影响最小，但当 Redis 所在的服务器宕机时，会丢失一部分数据，为了数据的安全性，一般我们也不采取这种配置</p></li><li><p><strong>everysec</strong><br>当<code>appendfsync</code>被设置为**<code>everysec</code>**时，redis 每秒执行一次<code>fsync</code>，这项工作在非主线程中完成</p><p>⚠️需要注意的是：对于用于追加写入<code>AOF</code>文件的<code>WRITE(2)</code>系统调用，如果执行时<code>fsync</code>仍在进行中，Redis 将使用一个缓冲区将<code>WRITE(2)</code>调用延迟两秒(因为在<code>Linux</code>上，如果正在对同一文件进行<code>fsync</code>，<code>WRITE</code>就会阻塞)；但如果<code>fsync</code>花费的时间太长，即使<code>fsync</code>仍在进行中，Redis 最终也会执行<code>WRITE(2)</code>调用，造成延迟</p><p>针对这种情况，Redis 提供了一个配置项，当子进程在追加写入<code>AOF</code>文件期间，可以让后台子线程不执行刷盘（不触发 fsync 系统调用）操作，也就是相当于在追加写<code>AOF</code>期间，临时把 <code>appendfsync</code> 设置为了 <code>no</code>，配置如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AOF rewrite 期间，AOF 后台子线程不进行刷盘操作</span></span><br><span class="line"><span class="comment"># 相当于在这期间，临时把 appendfsync 设置为了 none</span></span><br><span class="line">no-appendfsync-on-rewrite yes</span><br></pre></td></tr></table></figure><p>当然，开启这个配置项，在追加写<code>AOF</code>期间，如果实例发生宕机，就会丢失更多的数据</p></li><li><p><strong>always</strong><br>当<code>appendfsync</code>被设置为<code>always</code>时，每次写入操作时都执行<code>fsync</code>，完成后才会发送<code>response</code>回客户端(实际上，Redis 会尝试将同时执行的多个命令聚集到单个fsync中)<br>在这种模式下，性能通常非常差，如果一定要达到这个持久化的要求并使用这个模式，就需要使用能够在短时间内执行<code>fsync</code>的<code>高速磁盘</code>以及<code>文件系统实现</code></p></li></ul><p>大多数 Redis 用户使用<code>no</code>或<code>everysec</code></p><p>并且为了最小化<code>AOF</code>带来的延迟，最好也要<strong>避免其他进程在同一系统中执行I/O</strong>；当然，使用**<code>SSD磁盘</code>**也会有所帮助（加💰），但通常情况下，即使是非SSD磁盘，如果磁盘没有被其它进程占用，Redis 也能在写入<code>Append Only File</code>时保持良好的性能，因为 Redis 在写入<code>Append Only File</code>时不需要任何<code>seek</code>操作</p><p>我们可以使用<code>strace</code>命令查看<code>AOF</code>带来的延迟:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo strace -p $(pidof redis-server) -T -e trace=fdatasync</span><br></pre></td></tr></table></figure><p>上面的命令将展示 Redis 在<strong>主线程</strong>中执行的所有<code>fdatync(2)</code>系统调用，但当<code>appendfsync</code>配置选项设置为<code>everysec</code>时，我们监控不到<strong>后台线程</strong>执行的<code>fdatync(2)</code>；为此我们需将<code>-f option</code>加到上述命令中，这样就可以看到子线程执行的<code>fdatync(2)</code>了</p><p>如果需要的话，我们还可以将<code>write</code>添加到<code>trace</code>项中以监控<code>WRITE(2)</code>系统调用:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo strace -p $(pidof redis-server) -T -e trace=fdatasync,write</span><br></pre></td></tr></table></figure><p>但是，由于<code>WRITE(2)</code>也用于将数据写入客户端<code>socket</code>以回复客户端请求，该命令也会显示许多与磁盘I/O无关的内容；为了解决这个问题我们可以使用以下命令:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo strace -f -p $(pidof redis-server) -T -e trace=fdatasync,write 2&gt;&amp;1 | grep -v <span class="string">&#x27;0.0&#x27;</span> | grep -v unfinished</span><br></pre></td></tr></table></figure><h3 id="swap导致的延迟"><a class="markdownIt-Anchor" href="#swap导致的延迟"></a> SWAP导致的延迟</h3><p>Linux(以及许多其它现代操作系统)能够将内存页面从内存重新定位到磁盘，反之亦然，以便有效地使用系统内存</p><p>如果内核将 Redis 内存页从内存移动到<code>SWAP 分区</code>，则当存储在该内存页中的数据被 Redis 使用时(例如，访问存储在该内存页中的 key)，内核将停止 Redis 进程，以便将该内存页移回内存；这是一个涉及**<code>随机I/O</code>**的缓慢磁盘操作（与访问已在内存中的内存页相比慢一到两个数量级），并将导致 Redis 客户端的异常延迟</p><p><code>Linux 内核</code>执行<code>SWAP</code>主要有以下三个原因：</p><ul><li>系统已使用内存达到内存上限，有可能是 Redis 使用的内存超过了系统可用内存，也可能是其它进程导致的</li><li>Redis 实例的数据集或数据集的一部分几乎是完全空闲的（客户端从未访问过），因此内核可以交换内存中的空闲内存页到磁盘；这种问题非常少见，因为即使是中等速度的实例也会经常接触所有内存页，迫使内核将所有内存页保留在内存中</li><li>一些进程在系统上产生大量读写I/O。因为文件通常是缓存的，所以它往往会给内核带来增加文件系统缓存的压力，从而产生<code>SWAP</code>；当然，这里说的进程也包括可能产生大文件的<code>Redis RDB</code>和<code>AOF</code>后台线程</li></ul><p>我们可以通过以下命令查看 Redis 的<code>SWAP</code>情况：</p><p>首先我们获取到 <code>redis-server</code> 的<code>pid</code>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ redis-cli info | grep process_id</span><br><span class="line">process_id:9</span><br></pre></td></tr></table></figure><p>接下来查看<code>Redis Swap</code>的使用情况：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># $pid改为刚刚获取到的redis-server的pid</span></span><br><span class="line">cat /proc/<span class="variable">$pid</span>/smaps | egrep <span class="string">&#x27;^(Swap|Size)&#x27;</span></span><br></pre></td></tr></table></figure><p>产生类似下面的输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">Size:                316 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:                  4 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:                  8 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:                 40 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:                132 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:             720896 kB</span><br><span class="line">Swap:                 12 kB</span><br><span class="line">Size:               4096 kB</span><br><span class="line">Swap:                156 kB</span><br><span class="line">Size:               4096 kB</span><br><span class="line">Swap:                  8 kB</span><br><span class="line">Size:               4096 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:                  4 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:               1272 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:                  8 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:                  4 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:                 16 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:                 84 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:                  4 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:                  4 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:                  8 kB</span><br><span class="line">Swap:                  4 kB</span><br><span class="line">Size:                  8 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:                  4 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:                  4 kB</span><br><span class="line">Swap:                  4 kB</span><br><span class="line">Size:                144 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:                  4 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:                  4 kB</span><br><span class="line">Swap:                  4 kB</span><br><span class="line">Size:                 12 kB</span><br><span class="line">Swap:                  4 kB</span><br><span class="line">Size:                108 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:                  4 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:                  4 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:                272 kB</span><br><span class="line">Swap:                  0 kB</span><br><span class="line">Size:                  4 kB</span><br><span class="line">Swap:                  0 kB</span><br></pre></td></tr></table></figure><p>每一行 Size 表示 Redis 所用的一块内存大小，Size 下面的 Swap 就表示这块 Size 大小的内存有多少数据已经被换到磁盘上了</p><p>从上面的输出中可以看到，有一个<code>720896 kB</code>的映射仅交换了<code>12 kB</code>，另一个映射中交换了<code>156 kB</code>，这些 Swap 占对应 Size 的比例很小，所以基本不会产生任何问题</p><p>但如果存在<code>SWAP</code>比例较大的输出，那么 Redis 的延迟很大可能就是<code>SWAP</code>导致的</p><p>我们可以使用<code>vmstat</code>命令进一步验证：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ vmstat 1</span><br><span class="line">procs -----------memory---------- ---swap-- -----io---- -system-- ----cpu----</span><br><span class="line"> r  b   swpd   free   buff  cache   si   so    bi    bo   <span class="keyword">in</span>   cs us sy id wa</span><br><span class="line"> 0  0   3980 697932 147180 1406456    0    0     2     2    2    0  4  4 91  0</span><br><span class="line"> 0  0   3980 697428 147180 1406580    0    0     0     0 19088 16104  9  6 84  0</span><br><span class="line"> 0  0   3980 697296 147180 1406616    0    0     0    28 18936 16193  7  6 87  0</span><br><span class="line"> 0  0   3980 697048 147180 1406640    0    0     0     0 18613 15987  6  6 88  0</span><br><span class="line"> 2  0   3980 696924 147180 1406656    0    0     0     0 18744 16299  6  5 88  0</span><br><span class="line"> 0  0   3980 697048 147180 1406688    0    0     0     4 18520 15974  6  6 88  0</span><br></pre></td></tr></table></figure><p>我们看到<code>si</code>和<code>so</code>这两列，它们分别是内存中<code>SWAP</code>到文件的 Size 以及从文件中<code>SWAP</code>到内存的 Size；如果这两列中存在非零值，则表示系统中存在<code>SWAP</code>活动</p><p>最后我们还可以使用<code>iostat</code>命令查看系统的全局<code>I/O</code>活动：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ iostat -xk 1</span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">          13.55    0.04    2.92    0.53    0.00   82.95</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await  svctm  %util</span><br><span class="line">sda               0.77     0.00    0.01    0.00     0.40     0.00    73.65     0.00    3.62   2.58   0.00</span><br><span class="line">sdb               1.27     4.75    0.82    3.54    38.00    32.32    32.19     0.11   24.80   4.24   1.85</span><br></pre></td></tr></table></figure><p>💡 解决方案</p><p>这种情况下基本没有什么可以多说的解决方案，无非就两方面：</p><ol><li>加内存（加💰），没有什么是怼资源无法解决的</li><li>减少业务侧对 Redis 的使用量，包括调整过期时间、优化数据结构、调整缓存策略等等</li></ol><p>另一方面自然是做好 Redis 机器的内存监控以及<code>SWAP</code>事件监控，在内存不足及<code>SWAP</code>事件激增时及时告警</p><h3 id="内存碎片"><a class="markdownIt-Anchor" href="#内存碎片"></a> 内存碎片</h3><p>Redis <strong>内存碎片率（<code>used_memory_rss / used_memory</code>）大于1</strong>表示正在发生碎片，内存碎片率超过1.5表示碎片过多，Redis 实例消耗了其实际申请的物理内存的150%的内存；另一方面，如果<strong>内存碎片率低于1</strong>，则表示Redis需要的内存多于系统上的可用内存，这会导致SWAP操作，其中内存交换到磁盘的CPU时间成本将导致 Redis 延迟显著增加</p><p>💡 为什么会产生内存碎片</p><p>主要有两大原因：</p><ul><li><code>redis</code>自己实现的内存分配器：在<code>redis</code>中新建<code>key-value</code>值时，<code>redis</code>需要向操作系统申请内存，一般的进程在不需要使用申请的内存后，会直接释放掉、归还内存；但<code>redis</code>不一样，<code>redis</code>在使用完内存后并不会直接归还内存，而是放在<code>redis</code>自己实现的内存分配器中管理，这样就不需要每次都向操作系统申请内存了，实现了高性能；但另一方面，未归还的内存自然也就造成了<strong>内存碎片</strong></li><li><code>value</code>的更新：<code>redis</code>的每个<code>key-value</code>对初始化的内存大小是最适合的，当这个<code>value</code>改变的并且原来内存块不适用的时候，就需要重新分配内存了；而重新分配之后，就会有一部分内存<code>redis</code>无法正常回收，造成了<strong>内存碎片</strong></li></ul><p>我们可以通过执行 INFO 命令快速查询到一个 Redis 实例的内存碎片率(<strong><code>mem_fragmentation_ratio</code></strong>)：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[db0] &gt; INFO memory</span><br><span class="line"><span class="comment"># Memory</span></span><br><span class="line">used_memory:215489640</span><br><span class="line">used_memory_human:205.51M</span><br><span class="line">...</span><br><span class="line">**mem_fragmentation_ratio**:1.13</span><br><span class="line">mem_fragmentation_bytes:27071448</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>理想情况下，操作系统将在物理内存中分配一个连续的段，Redis 的内存碎片率等于1或略大于1；碎片率过大会导致内存无法有效利用，进而导致redis频繁进行内存分配和回收，从而导致用户请求延迟，并且这个延迟是不会计入<code>slowlog</code>的</p><p>💡 如何清理内存碎片</p><p>若在<code>Redis &lt; 4.0</code>的版本，如果内存碎片率高于1.5，直接重启 Redis 实例就可以让操作系统恢复之前因碎片而无法使用的内存；但在这种情况下，也许监控并发出告警就足够了，直接重启在大多数场景下并不适用；但当内存碎片率低于1时，我们就需要一个高级别的告警，以快速增加可用内存或减少内存使用量</p><p><code>Redis ≥ 4.0</code>开始，当 Redis 配置为使用包含的<code>jemalloc</code>副本时，可以使用主动碎片整理功能；它可以配置为在碎片达到一定百分比时启动，将数据复制到<strong>连续的内存区域</strong>并释放旧数据，从而减少内存碎片</p><p><code>redis-cli</code>开启自动内存碎片清理：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379[6]&gt; config <span class="built_in">set</span> activedefrag yes</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><p><code>redis.conf</code>中相关的配置项</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># Enabled active defragmentation</span><br><span class="line"># 碎片整理总开关</span><br><span class="line"># activedefrag yes</span><br><span class="line"></span><br><span class="line"># Minimum amount of fragmentation waste to start active defrag</span><br><span class="line"># 内存碎片达到多少的时候开启整理</span><br><span class="line">active-defrag-ignore-bytes 100mb</span><br><span class="line"></span><br><span class="line"># Minimum percentage of fragmentation to start active defrag</span><br><span class="line"># 碎片率达到百分之多少开启整理</span><br><span class="line">active-defrag-threshold-lower 10</span><br><span class="line"></span><br><span class="line"># Maximum percentage of fragmentation at which we use maximum effort</span><br><span class="line"># 碎片率小余多少百分比开启整理</span><br><span class="line">active-defrag-threshold-upper 100</span><br></pre></td></tr></table></figure><p>当然，在面对一些复杂的场景时我们希望能根据自己设计的策略来进行内存碎片清理，<code>redis</code>也提供了手动内存碎片清理的命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; memory purge</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><h3 id="绑定cpu单核"><a class="markdownIt-Anchor" href="#绑定cpu单核"></a> 绑定CPU单核</h3><p>很多时候，我们在部署服务时，为了提高服务性能，降低应用程序在多个 CPU 核心之间的上下文切换带来的性能损耗，通常采用的方案是进程绑定 CPU 的方式提高性能</p><p>但 <code>Vanilla Redis</code>并不适合绑定到单个CPU核心上</p><p>一般现代的服务器会有多个 CPU，而每个 CPU 又包含多个<code>物理核心</code>，每个<code>物理核心</code>又分为多个<code>逻辑核心</code>，每个物理核下的逻辑核共用 L1/L2 Cache</p><p>而Redis 会<code>fork</code>出非常消耗CPU的后台任务，如<code>BGSAVE</code>或<code>BGREWRITEAOF</code>、异步释放 fd、异步 AOF 刷盘、异步 lazy-free 等等</p><p>如果把 Redis 进程只绑定了一个 CPU 逻辑核心上，那么当 Redis 在进行数据持久化时，fork 出的子进程会**<code>继承父进程的 CPU 使用偏好</code>**</p><p><strong>此时子进程就要占用大量的CPU时间，与主进程发生 CPU 争抢，进而影响到主进程服务客户端请求，访问延迟变大</strong></p><p>💡 解决方案</p><ol><li><p>绑定多个逻辑核心</p><p>如果你确实想要绑定 CPU，可以优化的方案是，不要让 Redis 进程只绑定在一个 CPU 逻辑核上，而是绑定在多个逻辑核心上，而且，绑定的多个逻辑核心最好是同一个物理核心，这样它们还可以共用 <code>L1/L2 Cache</code></p><p>当然，即便我们把 Redis 绑定在多个逻辑核心上，也只能在一定程度上缓解主线程、子进程、后台线程在 CPU 资源上的竞争</p><p>因为这些子进程、子线程还是会在这多个逻辑核心上进行切换，依旧存在性能损耗</p></li><li><p>针对各个场景绑定固定的 CPU 逻辑核心</p><p>Redis 6.0 以上的版本中，我们可以通过以下配置，对主线程、后台线程、后台 RDB 进程、AOF rewrite 进程，绑定固定的 CPU 逻辑核心：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Redis Server 和 IO 线程绑定到 CPU核心 0,2,4,6</span></span><br><span class="line">server_cpulist 0-7:2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 后台子线程绑定到 CPU核心 1,3</span></span><br><span class="line">bio_cpulist 1,3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 后台 AOF rewrite 进程绑定到 CPU 核心 8,9,10,11</span></span><br><span class="line">aof_rewrite_cpulist 8-11</span><br><span class="line"></span><br><span class="line"><span class="comment"># 后台 RDB 进程绑定到 CPU 核心 1,10,11</span></span><br><span class="line"><span class="comment"># bgsave_cpulist 1,10-1</span></span><br></pre></td></tr></table></figure><p>如果使用的正好是 Redis 6.0 以上的版本，就可以通过以上配置，来进一步提高 Redis 性能；但一般来说，Redis 的性能已经足够优秀，除非对 Redis 的性能有更加严苛的要求，否则不建议绑定 CPU</p></li></ol><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> <strong>总结</strong></h1><p>Redis 排障是一个循序渐进的复杂流程，涉及到Redis 运行原理，设计架构以及操作系统，网络等等</p><p>作为业务方的 Redis 使用者，我们需要了解 Redis 的基本原理，如各个命令的时间复杂度、数据过期策略、数据淘汰策略以及读写分离架构等，从而更合理地使用 Redis 命令，并结合业务场景进行相关的性能优化</p><p>Redis 在性能优秀的同时，又是脆弱的；作为 Redis 的运维者，我们需要在部署 Redis 时，需要结合实际业务进行容量规划，预留足够的机器资源，配置良好的网络支持，还要对 Redis 机器和实例做好完善的监控，以保障 Redis 实例的稳定运行</p></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者:</span> <span class="post-copyright-info"><a href="mailto:undefined">Kevinello</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接:</span> <span class="post-copyright-info"><a href="http://kevinello.ltd/2023/03/05/Redis%E6%80%A7%E8%83%BD%E4%B9%8B%E5%B7%85%EF%BC%9A%E5%BB%B6%E8%BF%9F%E9%97%AE%E9%A2%98%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/">http://kevinello.ltd/2023/03/05/Redis性能之巅：延迟问题排障指南/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明:</span> <span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://kevinello.ltd" target="_blank">Kevinello</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/">数据库</a><a class="post-meta__tags" href="/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/">性能优化</a><a class="post-meta__tags" href="/tags/Redis/">Redis</a><a class="post-meta__tags" href="/tags/%E7%9B%91%E6%8E%A7/">监控</a></div><div class="post_share"><div class="social-share" data-image="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/02/28/202302281707283-c5d6b1.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/07/06/%E5%A6%82%E4%BD%95%E4%B8%BA%E7%A7%81%E6%9C%89%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BF%AB%E9%80%9F%E6%B2%89%E6%B7%80%E9%AB%98%E8%B4%A8%E9%87%8F%E6%95%B0%E6%8D%AE%E9%9B%86/"><img class="prev-cover" src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/09/07/202309071443770-70c1ed.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">如何为私有大语言模型快速沉淀高质量数据集</div></div></a></div><div class="next-post pull-right"><a href="/2023/03/05/clash-on-linux%E9%85%8D%E7%BD%AE/"><img class="next-cover" src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/03/05/202303051704184-34cc7e.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">clash-on-linux配置</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/02/28/%E5%AE%9E%E6%97%B6%E7%9B%91%E6%8E%A7Redis%EF%BC%9A%E4%BF%9D%E9%9A%9CRedis%E7%9A%84%E7%A8%B3%E5%AE%9A%E6%80%A7%E5%92%8C%E5%8F%AF%E9%9D%A0%E6%80%A7/" title="从Redis事务到Redis pipeline"><img class="cover" src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/02/28/202302281707283-c5d6b1.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-28</div><div class="title">从Redis事务到Redis pipeline</div></div></a></div><div><a href="/2021/04/11/Redis%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87%E7%9A%84%E4%BA%A7%E7%94%9F%E4%B8%8E%E6%B8%85%E7%90%86/" title="Redis内存碎片的产生与清理"><img class="cover" src="https://kevinello-1302687393.cos.ap-hongkong.myqcloud.com/img/20210411164926.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-04-11</div><div class="title">Redis内存碎片的产生与清理</div></div></a></div><div><a href="/2021/06/14/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%AE%9E%E7%8E%B0/" title="Redis分布式锁的基本实现"><img class="cover" src="https://kevinello-1302687393.cos.ap-hongkong.myqcloud.com/img/20210508140417.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-06-14</div><div class="title">Redis分布式锁的基本实现</div></div></a></div><div><a href="/2021/02/06/Redis%E7%9A%84%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5-%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/" title="Redis的过期策略&内存淘汰策略"><img class="cover" src="https://kevinello-1302687393.cos.ap-hongkong.myqcloud.com/img/street2.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-02-06</div><div class="title">Redis的过期策略&内存淘汰策略</div></div></a></div><div><a href="/2021/04/19/%E4%BB%8ERedis%E4%BA%8B%E5%8A%A1%E5%88%B0Redis-pipeline/" title="从Redis事务到Redis pipeline"><img class="cover" src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/02/28/202302281707283-c5d6b1.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-04-19</div><div class="title">从Redis事务到Redis pipeline</div></div></a></div><div><a href="/2022/01/10/%E9%9D%A2%E8%AF%95%E5%AE%98%E5%88%9D%E4%BD%93%E9%AA%8C/" title="面试官初体验"><img class="cover" src="https://kevinello-1302687393.cos.ap-hongkong.myqcloud.com/img/20220110130328.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-10</div><div class="title">面试官初体验</div></div></a></div></div></div><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i> <span>评论</span></div><div id="comment-switch"><span class="first-comment">Utterances</span><span class="switch-btn"></span><span class="second-comment">Twikoo</span></div></div><div class="comment-wrap"><div><div id="utterances-wrap"></div></div><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2022/04/11/myself-e3fde6.png" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">Kevinello</div><div class="author-info__description"></div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">51</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">97</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/kevinello"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/kevinello" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://space.bilibili.com/23149976" target="_blank" title="Bilibili"><i class="iconfont icon-bilibili-fill"></i></a><a class="social-icon" href="mailto:kevinello42@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%9C%80%E8%A6%81%E4%BA%86%E8%A7%A3%E7%9A%84%E8%AF%8D"><span class="toc-number">2.</span> <span class="toc-text">需要了解的词</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%8E%92%E9%99%A4%E6%97%A0%E5%85%B3%E5%8E%9F%E5%9B%A0"><span class="toc-number">3.</span> <span class="toc-text">排除无关原因</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95%E6%B5%81%E7%A8%8B"><span class="toc-number">3.1.</span> <span class="toc-text">测试流程</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BF%AB%E9%80%9F%E6%B8%85%E5%8D%95"><span class="toc-number">4.</span> <span class="toc-text">快速清单</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AF%BC%E8%87%B4redis-latency%E7%9A%84%E5%85%B7%E4%BD%93%E5%8E%9F%E5%9B%A0"><span class="toc-number">5.</span> <span class="toc-text">导致Redis Latency的具体原因</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%A4%8D%E6%9D%82%E5%BA%A6%E8%BF%87%E9%AB%98%E7%9A%84%E5%91%BD%E4%BB%A4-%E5%A4%A7%E5%9E%8B%E5%91%BD%E4%BB%A4"><span class="toc-number">5.0.1.</span> <span class="toc-text">使用复杂度过高的命令 &#x2F; 「大型」命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#bigkey"><span class="toc-number">5.0.2.</span> <span class="toc-text">Bigkey</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hotkey"><span class="toc-number">5.0.3.</span> <span class="toc-text">Hotkey</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#key%E9%9B%86%E4%B8%AD%E8%BF%87%E6%9C%9F"><span class="toc-number">5.0.4.</span> <span class="toc-text">Key集中过期</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A6%E5%8F%8Amaxmemory"><span class="toc-number">5.0.5.</span> <span class="toc-text">触及maxmemory</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%81%E4%B9%85%E5%8C%96%E8%80%97%E6%97%B6"><span class="toc-number">5.0.6.</span> <span class="toc-text">持久化耗时</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%80%E5%90%AF%E5%86%85%E5%AD%98%E5%A4%A7%E9%A1%B5"><span class="toc-number">5.0.7.</span> <span class="toc-text">开启内存大页</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#aof%E5%92%8C%E7%A3%81%E7%9B%98io%E9%80%A0%E6%88%90%E7%9A%84%E5%BB%B6%E8%BF%9F"><span class="toc-number">5.0.8.</span> <span class="toc-text">AOF和磁盘I&#x2F;O造成的延迟</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#swap%E5%AF%BC%E8%87%B4%E7%9A%84%E5%BB%B6%E8%BF%9F"><span class="toc-number">5.0.9.</span> <span class="toc-text">SWAP导致的延迟</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87"><span class="toc-number">5.0.10.</span> <span class="toc-text">内存碎片</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%91%E5%AE%9Acpu%E5%8D%95%E6%A0%B8"><span class="toc-number">5.0.11.</span> <span class="toc-text">绑定CPU单核</span></a></li></ol></li></ol><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">6.</span> <span class="toc-text">总结</span></a></li></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/09/06/LLM%E8%BF%9C%E4%B8%8D%E4%BB%85%E4%BB%85%E6%98%AFChat%20Model%E2%80%94%E2%80%94LangChain%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E4%B8%8E%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/" title="LLM远不仅仅是Chat Model——LangChain基本概念与使用示例"><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/09/07/202309071425723-3c7e69.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="LLM远不仅仅是Chat Model——LangChain基本概念与使用示例"></a><div class="content"><a class="title" href="/2023/09/06/LLM%E8%BF%9C%E4%B8%8D%E4%BB%85%E4%BB%85%E6%98%AFChat%20Model%E2%80%94%E2%80%94LangChain%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E4%B8%8E%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/" title="LLM远不仅仅是Chat Model——LangChain基本概念与使用示例">LLM远不仅仅是Chat Model——LangChain基本概念与使用示例</a><time datetime="2023-09-05T16:08:35.000Z" title="发表于 2023-09-06 00:08:35">2023-09-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/07/06/%E5%A6%82%E4%BD%95%E4%B8%BA%E7%A7%81%E6%9C%89%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BF%AB%E9%80%9F%E6%B2%89%E6%B7%80%E9%AB%98%E8%B4%A8%E9%87%8F%E6%95%B0%E6%8D%AE%E9%9B%86/" title="如何为私有大语言模型快速沉淀高质量数据集"><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/09/07/202309071443770-70c1ed.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="如何为私有大语言模型快速沉淀高质量数据集"></a><div class="content"><a class="title" href="/2023/07/06/%E5%A6%82%E4%BD%95%E4%B8%BA%E7%A7%81%E6%9C%89%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BF%AB%E9%80%9F%E6%B2%89%E6%B7%80%E9%AB%98%E8%B4%A8%E9%87%8F%E6%95%B0%E6%8D%AE%E9%9B%86/" title="如何为私有大语言模型快速沉淀高质量数据集">如何为私有大语言模型快速沉淀高质量数据集</a><time datetime="2023-07-05T16:08:35.000Z" title="发表于 2023-07-06 00:08:35">2023-07-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/05/Redis%E6%80%A7%E8%83%BD%E4%B9%8B%E5%B7%85%EF%BC%9A%E5%BB%B6%E8%BF%9F%E9%97%AE%E9%A2%98%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/" title="Redis性能之巅：延迟问题排障指南"><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/02/28/202302281707283-c5d6b1.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Redis性能之巅：延迟问题排障指南"></a><div class="content"><a class="title" href="/2023/03/05/Redis%E6%80%A7%E8%83%BD%E4%B9%8B%E5%B7%85%EF%BC%9A%E5%BB%B6%E8%BF%9F%E9%97%AE%E9%A2%98%E6%8E%92%E9%9A%9C%E6%8C%87%E5%8D%97/" title="Redis性能之巅：延迟问题排障指南">Redis性能之巅：延迟问题排障指南</a><time datetime="2023-03-05T09:08:07.000Z" title="发表于 2023-03-05 17:08:07">2023-03-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/05/clash-on-linux%E9%85%8D%E7%BD%AE/" title="clash-on-linux配置"><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/03/05/202303051704184-34cc7e.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="clash-on-linux配置"></a><div class="content"><a class="title" href="/2023/03/05/clash-on-linux%E9%85%8D%E7%BD%AE/" title="clash-on-linux配置">clash-on-linux配置</a><time datetime="2023-03-05T07:34:11.000Z" title="发表于 2023-03-05 15:34:11">2023-03-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/02/28/%5Bvscode%20issue%5D%20Golang%20Debug%20%E6%97%A0%E6%B3%95%E5%91%BD%E4%B8%AD%E6%96%AD%E7%82%B9/" title="\[vscode issue\] Golang Debug 无法命中断点"><img src="https://kevinello-1302687393.file.myqcloud.com/picgo/2023/02/28/202302281702991-ae1947.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="\[vscode issue\] Golang Debug 无法命中断点"></a><div class="content"><a class="title" href="/2023/02/28/%5Bvscode%20issue%5D%20Golang%20Debug%20%E6%97%A0%E6%B3%95%E5%91%BD%E4%B8%AD%E6%96%AD%E7%82%B9/" title="\[vscode issue\] Golang Debug 无法命中断点">\[vscode issue\] Golang Debug 无法命中断点</a><time datetime="2023-02-28T09:15:07.000Z" title="发表于 2023-02-28 17:15:07">2023-02-28</time></div></div></div></div></div></div></main><footer id="footer" style="background-image:url(https://kevinello-1302687393.file.myqcloud.com/picgo/2023/02/28/202302281707283-c5d6b1.png)"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By Kevinello</div><div class="framework-info"><span>框架</span> <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题</span> <a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">🥳 🥳 🥳 🥳 🥳</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Algolia</span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script><script src="/js/search/optimized_algolia.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>function loadUtterances () {
  let ele = document.createElement('script')
  ele.setAttribute('id', 'utterances_comment')
  ele.setAttribute('src', 'https://utteranc.es/client.js')
  ele.setAttribute('repo', 'Kevinello/gitalk')
  ele.setAttribute('issue-term', 'pathname')
  let nowTheme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'photon-dark' : 'github-light'
  ele.setAttribute('theme', nowTheme)
  ele.setAttribute('crossorigin', 'anonymous')
  ele.setAttribute('async', 'true')
  document.getElementById('utterances-wrap').insertAdjacentElement('afterbegin',ele)
}

function utterancesTheme () {
  const iframe = document.querySelector('.utterances-frame')
  if (iframe) {
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'photon-dark' : 'github-light'
    const message = {
      type: 'set-theme',
      theme: theme
    };
    iframe.contentWindow.postMessage(message, 'https://utteranc.es');
  }
}

if ('Utterances' === 'Utterances' || !false) {
  if (false) btf.loadComment(document.getElementById('utterances-wrap'), loadUtterances)
  else loadUtterances()
} else {
  function loadOtherComment () {
    loadUtterances()
  }
}</script><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'blog-comments-9gil6as164013b6c',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.vemoji)'))
      }
    }, null))
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'blog-comments-9gil6as164013b6c',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      document.getElementById('twikoo-count').innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runFn)
  }

  if ('Utterances' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script async data-pjax src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>